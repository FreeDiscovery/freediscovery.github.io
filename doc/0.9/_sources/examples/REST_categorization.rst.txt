

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['filenames', 'id']
       => dsid = edbe41ff61114e36

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/edbe41ff61114e36

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/edbe41ff61114e36

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/edbe41ff61114e36
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: True
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = b1836cca6bb445ad
      => SVD decomposition with 100 dimensions explaining 76.49 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 0fdf4974018740c6
        => Training scores: MAP = 0.907, ROC-AUC = 0.900, recall @20%: 0.800 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/0fdf4974018740c6
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/0fdf4974018740c6/predict
                 category  score
    document_id                 
    0            negative  0.641
    1            negative  0.697
    4            negative  0.675
    9            negative  0.549
    16           negative  0.665
    25           negative  0.666
    36           negative  0.680
    49           negative  0.678
    64           negative  0.667
    81           negative  0.695
    100          negative  0.659
    121          negative  0.740
    144          negative  0.730
    169          negative  0.718
    196          negative  0.722
    225          negative  0.694
    256          negative  0.738
    289          negative  0.739
    324          negative  0.707
    361          negative  0.745
    400          negative  0.696
    441          negative  0.723
    484          negative  0.743
    529          negative  0.731
    576          negative  0.707
    625          negative  0.732
    676          negative  0.737
    729          negative  0.729
    784          negative  0.739
    841          negative  0.740
    ...               ...    ...
    5929225      negative  0.750
    5934096      negative  0.681
    5938969      negative  0.706
    5943844      negative  0.704
    5948721      negative  0.695
    5953600      negative  0.718
    5958481      negative  0.689
    5963364      negative  0.715
    5968249      negative  0.658
    5973136      negative  0.684
    5978025      negative  0.678
    5982916      negative  0.704
    5987809      negative  0.658
    5992704      negative  0.682
    5997601      negative  0.670
    6002500      negative  0.701
    6007401      negative  0.688
    6012304      negative  0.710
    6017209      negative  0.664
    6022116      negative  0.686
    6027025      negative  0.695
    6031936      negative  0.646
    6036849      negative  0.706
    6041764      negative  0.659
    6046681      negative  0.691
    6051600      negative  0.684
    6056521      negative  0.683
    6061444      negative  0.725
    6066369      negative  0.680
    6071296      negative  0.714

    [2465 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.948, ROC-AUC = 0.999, recall @20%: 1.000 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = bbd680b8d72244fb
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/bbd680b8d72244fb
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/bbd680b8d72244fb/predict
                 category  nearest_document_id  score
    document_id                                      
    0            negative              2560000  0.399
    1            negative               225625  0.346
    4            negative              3048516  0.416
    9            positive                    9  1.000
    16           positive                    9  0.591
    25           negative              2442969  0.362
    36           negative              2560000  0.517
    49           negative              1449616  0.370
    64           negative              1787569  0.435
    81           negative                   81  1.000
    100          positive                    9  0.489
    121          negative                 1024  0.348
    144          negative                 1024  0.334
    169          negative              4157521  0.369
    196          negative              4157521  0.985
    225          negative              2442969  0.426
    256          negative                 1024  0.362
    289          negative              3632836  0.318
    324          negative              1315609  0.343
    361          negative              1218816  0.454
    400          negative              6007401  0.442
    441          negative              5175625  0.725
    484          negative              1787569  0.332
    529          negative              3254416  0.329
    576          positive               820836  0.371
    625          negative              5175625  0.485
    676          negative                 1024  0.314
    729          negative               131044  0.367
    784          negative                 1024  0.349
    841          negative              3632836  0.314
    ...               ...                  ...    ...
    5929225      negative              2050624  0.283
    5934096      negative               378225  0.520
    5938969      negative               378225  0.397
    5943844      negative              1449616  0.348
    5948721      negative              1247689  0.392
    5953600      negative              1247689  0.367
    5958481      negative              2259009  0.425
    5963364      negative               131044  0.345
    5968249      negative                   81  0.405
    5973136      negative                   81  0.333
    5978025      negative                   81  0.451
    5982916      negative                   81  0.360
    5987809      negative              5354596  0.448
    5992704      negative              5354596  0.324
    5997601      positive                    9  0.537
    6002500      negative              5697769  0.673
    6007401      negative              6007401  1.000
    6012304      negative              6007401  0.697
    6017209      negative              1787569  0.461
    6022116      negative              6007401  0.394
    6027025      positive                    9  0.477
    6031936      positive                    9  0.739
    6036849      negative              2442969  0.488
    6041764      negative              5354596  0.341
    6046681      negative              2076481  0.714
    6051600      negative              2076481  0.349
    6056521      negative                 6561  0.313
    6061444      negative              2076481  0.366
    6066369      negative              6007401  0.321
    6071296      negative              2076481  0.431

    [2465 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.648, ROC-AUC = 0.802, recall @20%: 0.750 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/edbe41ff61114e36




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])} \
                                       for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'dataset_definition': dataset_definition,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(pd.DataFrame(input_ds['training_set'])\
                                 .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)


            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                          'y_pred': res['data'] }).json()


            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  18.276 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
