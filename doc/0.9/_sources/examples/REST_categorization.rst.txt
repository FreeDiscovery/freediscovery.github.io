

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['filenames', 'id']
       => dsid = 7a02c0bd32f449f0

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/7a02c0bd32f449f0

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/7a02c0bd32f449f0

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/7a02c0bd32f449f0
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: None
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: True
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = 71173b382aaf4840
      => SVD decomposition with 100 dimensions explaining 99.79 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = ef3447e6a3664dab
        => Training scores: MAP = 0.537, ROC-AUC = 0.500, recall @20%: 0.600 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/ef3447e6a3664dab
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/ef3447e6a3664dab/predict
                 category  score
    document_id                 
    0            negative  0.700
    1            negative  0.700
    4            negative  0.700
    9            negative  0.700
    16           negative  0.700
    25           negative  0.700
    36           negative  0.700
    49           negative  0.700
    64           negative  0.700
    81           negative  0.700
    100          negative  0.700
    121          negative  0.700
    144          negative  0.700
    169          negative  0.700
    196          negative  0.700
    225          negative  0.700
    256          negative  0.700
    289          negative  0.700
    324          negative  0.700
    361          negative  0.700
    400          negative  0.700
    441          negative  0.700
    484          negative  0.700
    529          negative  0.700
    576          negative  0.700
    625          negative  0.700
    676          negative  0.700
    729          negative  0.700
    784          negative  0.700
    841          negative  0.700
    ...               ...    ...
    5929225      negative  0.700
    5934096      negative  0.700
    5938969      negative  0.700
    5943844      negative  0.700
    5948721      negative  0.700
    5953600      negative  0.700
    5958481      negative  0.700
    5963364      negative  0.700
    5968249      negative  0.700
    5973136      negative  0.700
    5978025      negative  0.700
    5982916      negative  0.700
    5987809      negative  0.700
    5992704      negative  0.700
    5997601      negative  0.700
    6002500      negative  0.700
    6007401      negative  0.700
    6012304      negative  0.700
    6017209      negative  0.700
    6022116      negative  0.700
    6027025      negative  0.700
    6031936      negative  0.700
    6036849      negative  0.700
    6041764      negative  0.700
    6046681      negative  0.700
    6051600      negative  0.700
    6056521      negative  0.700
    6061444      negative  0.700
    6066369      negative  0.700
    6071296      negative  0.700

    [2465 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.214, ROC-AUC = 0.908, recall @20%: 0.833 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = ff759e5da6df42b7
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/ff759e5da6df42b7
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/ff759e5da6df42b7/predict
                 category  nearest_document_id  score
    document_id                                      
    0            positive              3207681  0.871
    1            negative              3254416  0.398
    4            negative               378225  0.978
    9            positive                    9  1.000
    16           positive                    9  0.959
    25           positive                    9  0.977
    36           positive                    9  0.962
    49           positive                    9  0.983
    64           negative              1787569  0.979
    81           negative                   81  1.000
    100          positive                    9  0.992
    121          negative              4498641  0.427
    144          negative              4498641  0.422
    169          negative              4157521  0.414
    196          negative              4157521  0.980
    225          negative               131044  0.876
    256          negative              4498641  0.324
    289          negative              4498641  0.366
    324          negative               131044  0.616
    361          negative               131044  0.638
    400          negative               131044  0.881
    441          negative              5175625  0.683
    484          negative              3254416  0.447
    529          negative              3254416  0.454
    576          negative               131044  0.638
    625          negative              5175625  0.377
    676          negative              4498641  0.390
    729          negative               938961  0.514
    784          negative              4498641  0.327
    841          negative              4498641  0.362
    ...               ...                  ...    ...
    5929225      negative              4511376  0.317
    5934096      positive                    9  0.970
    5938969      negative              2436721  0.873
    5943844      negative              2436721  0.881
    5948721      negative                   81  0.973
    5953600      negative              2436721  0.902
    5958481      negative                   81  0.975
    5963364      negative              2436721  0.894
    5968249      positive                    9  0.953
    5973136      negative              2436721  0.853
    5978025      positive                    9  0.949
    5982916      negative              1449616  0.861
    5987809      positive                    9  0.971
    5992704      negative              5697769  0.913
    5997601      positive                    9  0.992
    6002500      negative              1449616  0.891
    6007401      negative              6007401  1.000
    6012304      negative              2436721  0.846
    6017209      negative              2788900  0.937
    6022116      negative              2436721  0.793
    6027025      negative              2436721  0.948
    6031936      positive                    9  0.996
    6036849      negative              2436721  0.870
    6041764      positive                    9  0.972
    6046681      negative              2076481  0.900
    6051600      negative              2076481  0.623
    6056521      negative               136161  0.525
    6061444      negative              2007889  0.583
    6066369      negative              2076481  0.542
    6071296      negative              2076481  0.593

    [2465 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.511, ROC-AUC = 0.649, recall @20%: 0.583 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/7a02c0bd32f449f0




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])} \
                                       for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'dataset_definition': dataset_definition,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(pd.DataFrame(input_ds['training_set'])\
                                 .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)


            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                          'y_pred': res['data'] }).json()


            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  16.804 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
