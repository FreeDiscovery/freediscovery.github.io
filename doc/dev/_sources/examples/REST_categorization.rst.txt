

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['filenames', 'id']
       => dsid = a32c20e2dd6a4796

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/a32c20e2dd6a4796

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/a32c20e2dd6a4796

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/a32c20e2dd6a4796
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: True
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = e981d8650e03440e
      => SVD decomposition with 100 dimensions explaining 76.49 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = d7a0828a8cfa4960
        => Training scores: MAP = 0.907, ROC-AUC = 0.900, recall @20%: 0.800 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/d7a0828a8cfa4960
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/d7a0828a8cfa4960/predict
                 category  score
    document_id                 
    0            negative  0.641
    1            negative  0.697
    4            negative  0.675
    9            negative  0.549
    16           negative  0.665
    25           negative  0.666
    36           negative  0.680
    49           negative  0.678
    64           negative  0.667
    81           negative  0.695
    100          negative  0.659
    121          negative  0.740
    144          negative  0.730
    169          negative  0.718
    196          negative  0.722
    225          negative  0.694
    256          negative  0.738
    289          negative  0.739
    324          negative  0.707
    361          negative  0.745
    400          negative  0.696
    441          negative  0.723
    484          negative  0.743
    529          negative  0.731
    576          negative  0.707
    625          negative  0.732
    676          negative  0.737
    729          negative  0.729
    784          negative  0.739
    841          negative  0.740
    ...               ...    ...
    5929225      negative  0.750
    5934096      negative  0.681
    5938969      negative  0.706
    5943844      negative  0.704
    5948721      negative  0.695
    5953600      negative  0.718
    5958481      negative  0.689
    5963364      negative  0.715
    5968249      negative  0.658
    5973136      negative  0.684
    5978025      negative  0.678
    5982916      negative  0.704
    5987809      negative  0.658
    5992704      negative  0.682
    5997601      negative  0.670
    6002500      negative  0.701
    6007401      negative  0.688
    6012304      negative  0.710
    6017209      negative  0.664
    6022116      negative  0.686
    6027025      negative  0.695
    6031936      negative  0.646
    6036849      negative  0.706
    6041764      negative  0.659
    6046681      negative  0.691
    6051600      negative  0.684
    6056521      negative  0.683
    6061444      negative  0.725
    6066369      negative  0.680
    6071296      negative  0.714

    [2465 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.948, ROC-AUC = 0.999, recall @20%: 1.000 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = e8e99733ad1b4387
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/e8e99733ad1b4387
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/e8e99733ad1b4387/predict
                 category  nearest_document_id  score
    document_id                                      
    0            negative              4272489  0.406
    1            negative              4260096  0.330
    4            negative              3048516  0.403
    9            positive                    9  1.000
    16           positive                    9  0.557
    25           negative              2442969  0.352
    36           negative              2560000  0.519
    49           negative              1449616  0.372
    64           negative              1787569  0.420
    81           negative                   81  1.000
    100          positive                    9  0.486
    121          negative                 1024  0.342
    144          negative                 1024  0.328
    169          negative              4157521  0.378
    196          negative              4157521  0.986
    225          negative              2442969  0.417
    256          negative                 1024  0.354
    289          negative               498436  0.322
    324          negative                 9801  0.334
    361          negative              1218816  0.468
    400          negative              6007401  0.444
    441          negative              5175625  0.719
    484          negative              3254416  0.353
    529          negative              3254416  0.350
    576          negative              4498641  0.373
    625          negative              5175625  0.473
    676          negative                 1024  0.304
    729          negative               131044  0.369
    784          negative                 1024  0.345
    841          negative               498436  0.320
    ...               ...                  ...    ...
    5929225      negative              2007889  0.302
    5934096      negative               378225  0.551
    5938969      negative               378225  0.403
    5943844      negative               378225  0.374
    5948721      negative              1247689  0.387
    5953600      negative              1247689  0.362
    5958481      negative              2259009  0.415
    5963364      negative               131044  0.344
    5968249      negative                   81  0.386
    5973136      negative                   81  0.317
    5978025      negative                   81  0.402
    5982916      negative                   81  0.325
    5987809      negative              5354596  0.420
    5992704      negative              1263376  0.316
    5997601      negative               378225  0.525
    6002500      negative              5697769  0.650
    6007401      negative              6007401  1.000
    6012304      negative              6007401  0.696
    6017209      negative              1787569  0.467
    6022116      negative              6007401  0.402
    6027025      positive                    9  0.460
    6031936      positive                    9  0.725
    6036849      negative              2442969  0.505
    6041764      negative               378225  0.350
    6046681      negative              2076481  0.730
    6051600      negative              2076481  0.356
    6056521      positive              1096209  0.312
    6061444      negative              2076481  0.363
    6066369      negative              4260096  0.332
    6071296      negative              2076481  0.440

    [2465 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.644, ROC-AUC = 0.802, recall @20%: 0.750 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/a32c20e2dd6a4796




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])} \
                                       for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'dataset_definition': dataset_definition,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(pd.DataFrame(input_ds['training_set'])\
                                 .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)


            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                          'y_pred': res['data'] }).json()


            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  18.163 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
