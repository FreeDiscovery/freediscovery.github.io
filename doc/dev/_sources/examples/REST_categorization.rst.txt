

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the test dataset
     GET http://localhost:5001/api/v0/datasets/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received [u'id', u'filenames']
       => dsid = 664b2d9c83444b44

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/664b2d9c83444b44

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/664b2d9c83444b44

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/664b2d9c83444b44
         - binary: False
         - n_jobs: 1
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - use_hashing: True
         - min_df: 0.0
         - analyzer: word
         - n_samples: 2465
         - ngram_range: [1, 1]
         - max_df: 1.0
         - chunk_size: 5000
         - use_idf: False
         - stop_words: None
         - n_features: 100001
         - n_samples_processed: 2465
         - sublinear_tf: True
         - norm: None

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = d40d1f65b511465d
      => SVD decomposition with 100 dimensions explaining 99.79 % variabilty of the data

    3.a. Train the categorization model
       5 relevant, 63 non-relevant files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = b9adaeb746de4dbb
        => Training scores: MAP = 0.683, ROC-AUC = 0.892, F1= 0.000

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/b9adaeb746de4dbb
         - method: LinearSVC
         - options: {'loss': 'squared_hinge', 'C': 1.0, 'verbose': 0, 'intercept_scaling': 1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'multi_class': 'ovr', 'random_state': None, 'dual': True, 'tol': 0.0001, 'class_weight': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/b9adaeb746de4dbb/predict
                 document_id  score
    internal_id                    
    0                      0 -0.846
    1                      1 -0.846
    2                      2 -0.846
    3                      3 -0.846
    4                      4 -0.846
    5                      5 -0.846
    6                      6 -0.846
    7                      7 -0.846
    8                      8 -0.846
    9                      9 -0.846
    10                    10 -0.846
    11                    11 -0.846
    12                    12 -0.846
    13                    13 -0.847
    14                    14 -0.846
    15                    15 -0.846
    16                    16 -0.847
    17                    17 -0.846
    18                    18 -0.846
    19                    19 -0.846
    20                    20 -0.846
    21                    21 -0.847
    22                    22 -0.846
    23                    23 -0.846
    24                    24 -0.846
    25                    25 -0.847
    26                    26 -0.846
    27                    27 -0.846
    28                    28 -0.847
    29                    29 -0.846
    ...                  ...    ...
    2435                2435 -0.849
    2436                2436 -0.846
    2437                2437 -0.846
    2438                2438 -0.846
    2439                2439 -0.846
    2440                2440 -0.846
    2441                2441 -0.846
    2442                2442 -0.846
    2443                2443 -0.846
    2444                2444 -0.846
    2445                2445 -0.846
    2446                2446 -0.846
    2447                2447 -0.846
    2448                2448 -0.846
    2449                2449 -0.846
    2450                2450 -0.846
    2451                2451 -0.846
    2452                2452 -0.846
    2453                2453 -0.846
    2454                2454 -0.846
    2455                2455 -0.846
    2456                2456 -0.846
    2457                2457 -0.846
    2458                2458 -0.846
    2459                2459 -0.846
    2460                2460 -0.846
    2461                2461 -0.846
    2462                2462 -0.846
    2463                2463 -0.846
    2464                2464 -0.846

    [2465 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.006, ROC-AUC = 0.545
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 225f95ee00544ab3
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, F1= 1.000

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/225f95ee00544ab3
         - method: NearestNeighbor
         - options: {'ranking': None, 'n_jobs': None, 'radius': None, 'leaf_size': None, 'algorithm': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/225f95ee00544ab3/predict
                 document_id  nn_negative__distance  nn_negative__document_id  nn_positive__distance  nn_positive__document_id  score
    internal_id                                                                                                                      
    0                      0                  0.220                        52                  0.200                         3  0.900
    1                      1                  0.576                        53                  0.644                         4 -0.712
    2                      2                  0.084                        21                  0.086                         0 -0.958
    3                      3                  0.062                        21                  0.000                         0  1.000
    4                      4                  0.123                        21                  0.117                         0  0.941
    5                      5                  0.103                        21                  0.088                         0  0.956
    6                      6                  0.132                        49                  0.116                         0  0.942
    7                      7                  0.087                        37                  0.071                         0  0.964
    8                      8                  0.079                        37                  0.076                         0  0.962
    9                      9                  0.000                         5                  0.102                         0 -1.000
    10                    10                  0.092                        37                  0.051                         0  0.975
    11                    11                  0.577                        58                  0.684                         4 -0.711
    12                    12                  0.585                        58                  0.664                         4 -0.707
    13                    13                  0.587                        44                  0.659                         3 -0.707
    14                    14                  0.077                        55                  0.619                         3 -0.962
    15                    15                  0.222                        12                  0.439                         1 -0.889
    16                    16                  0.646                        58                  0.698                         4 -0.677
    17                    17                  0.628                        58                  0.667                         4 -0.686
    18                    18                  0.426                        12                  0.568                         1 -0.787
    19                    19                  0.405                        12                  0.612                         1 -0.798
    20                    20                  0.219                        12                  0.468                         1 -0.890
    21                    21                  0.363                        63                  0.677                         3 -0.819
    22                    22                  0.531                        58                  0.653                         4 -0.735
    23                    23                  0.534                        58                  0.655                         4 -0.733
    24                    24                  0.410                        12                  0.549                         4 -0.795
    25                    25                  0.608                        63                  0.711                         4 -0.696
    26                    26                  0.603                        58                  0.688                         4 -0.698
    27                    27                  0.494                        26                  0.601                         2 -0.753
    28                    28                  0.642                        23                  0.703                         4 -0.679
    29                    29                  0.629                         7                  0.670                         4 -0.686
    ...                  ...                    ...                       ...                    ...                       ...    ...
    2435                2435                  0.662                        59                  0.680                         1 -0.669
    2436                2436                  0.108                        67                  0.099                         0  0.950
    2437                2437                  0.215                        47                  0.338                         4 -0.892
    2438                2438                  0.208                        47                  0.307                         0 -0.896
    2439                2439                  0.096                         5                  0.111                         0 -0.952
    2440                2440                  0.192                        47                  0.313                         0 -0.904
    2441                2441                  0.089                         5                  0.106                         0 -0.955
    2442                2442                  0.199                        47                  0.302                         0 -0.900
    2443                2443                  0.129                        52                  0.123                         0  0.939
    2444                2444                  0.238                        47                  0.325                         4 -0.881
    2445                2445                  0.139                        37                  0.127                         0  0.937
    2446                2446                  0.236                        35                  0.332                         0 -0.882
    2447                2447                  0.112                        64                  0.096                         0  0.952
    2448                2448                  0.184                        66                  0.319                         0 -0.908
    2449                2449                  0.088                        37                  0.056                         0  0.972
    2450                2450                  0.179                        35                  0.282                         0 -0.910
    2451                2451                  0.000                        67                  0.127                         0 -1.000
    2452                2452                  0.232                        47                  0.336                         0 -0.884
    2453                2453                  0.155                        51                  0.199                         0 -0.923
    2454                2454                  0.283                        47                  0.326                         4 -0.859
    2455                2455                  0.136                        47                  0.317                         0 -0.932
    2456                2456                  0.057                        21                  0.034                         0  0.983
    2457                2457                  0.219                        47                  0.313                         0 -0.891
    2458                2458                  0.116                        21                  0.095                         0  0.953
    2459                2459                  0.184                        42                  0.535                         2 -0.908
    2460                2460                  0.412                        42                  0.512                         3 -0.794
    2461                2461                  0.487                        13                  0.515                         2 -0.756
    2462                2462                  0.431                        39                  0.616                         0 -0.784
    2463                2463                  0.470                        42                  0.516                         2 -0.765
    2464                2464                  0.437                        42                  0.552                         2 -0.782

    [2465 rows x 6 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.006, ROC-AUC = 0.350

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/664b2d9c83444b44




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the test dataset")
        url = BASE_URL + '/datasets/{}'.format(dataset_name)
        print(" GET", url)
        res = requests.get(url, json={'return_file_path': True}).json()

        # To use a custom dataset, simply specify the following variables
        seed_document_id = res['seed_document_id']
        seed_y = res['seed_y']
        ground_truth_y = res['ground_truth_y']

        # create a custom dataset definition for ingestion
        dataset_definition = []
        for document_id, fname in zip(res['document_id'], res['file_path']):
            dataset_definition.append({'document_id': document_id,
                                      'rendering_id': 0,
                                      'file_path': fname})

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'dataset_definition': dataset_definition,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))
        # this step is not necessary anymore
        #method = BASE_URL + "/feature-extraction/{}/id-mapping/flat".format(dsid)
        #res = requests.get(method, data={'document_id': seed_document_id})
        #seed_internal_id = res.json()['internal_id']


        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} relevant, {} non-relevant files".format(seed_y.count(1), seed_y.count(0)))

        seed_index_nested = [{'document_id': internal_id, 'y': y} \
                                    for internal_id, y in zip(seed_document_id, seed_y)]

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'index_nested': seed_index_nested,
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, F1= {f1:.3f}'.format(**res))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'y']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            if method == "NearestNeighbor":

                def flatten_dict(d, parent_key='', sep='__'):
                    """Flatten a nested dictionary """
                    import collections
                    items = []
                    for k, v in d.items():
                        new_key = parent_key + sep + k if parent_key else k
                        if isinstance(v, collections.MutableMapping):
                            items.extend(flatten_dict(v, new_key, sep=sep).items())
                        else:
                            items.append((new_key, v))
                    return dict(items)
            
                data = [flatten_dict(el) for el in res['data']]
            else:
                data = res['data']

            df = pd.DataFrame(data).set_index('internal_id')
            if method == "NearestNeighbor":
                df = df[['document_id', 'nn_negative__distance', 'nn_negative__document_id',
                      'nn_positive__distance', 'nn_positive__document_id', 'score']]

            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.get(url, json={'y_true': ground_truth_y,
                                          'y_pred': df.score.values.tolist(),
                                         } ).json()





            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}'.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 1 minutes  8.106 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
