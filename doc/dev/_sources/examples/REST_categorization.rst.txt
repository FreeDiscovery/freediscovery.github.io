

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['filenames', 'id']
       => dsid = e471fdfa0237449e

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/e471fdfa0237449e

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/e471fdfa0237449e

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/e471fdfa0237449e
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: True
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = e2dbe4236da54ad2
      => SVD decomposition with 100 dimensions explaining 76.49 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 801ed41132c94a8b
        => Training scores: MAP = 0.907, ROC-AUC = 0.900, recall @20%: 0.800 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/801ed41132c94a8b
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/801ed41132c94a8b/predict
                 category  score
    document_id                 
    454276       negative  0.775
    568516       negative  0.775
    2845969      negative  0.765
    1803649      negative  0.765
    573049       negative  0.763
    1723969      negative  0.762
    319225       negative  0.761
    3290596      negative  0.761
    3326976      negative  0.761
    3243601      negative  0.761
    806404       negative  0.760
    118336       negative  0.760
    1098304      negative  0.760
    4405801      negative  0.760
    600625       negative  0.759
    3225616      negative  0.759
    3496900      negative  0.759
    877969       negative  0.758
    885481       negative  0.758
    1077444      negative  0.757
    3636649      negative  0.757
    10000        negative  0.757
    5230369      negative  0.757
    1557504      negative  0.757
    3545689      negative  0.756
    1285956      negative  0.756
    1052676      negative  0.756
    5166529      negative  0.755
    106929       negative  0.755
    1100401      negative  0.755
    ...               ...    ...
    229441       negative  0.627
    817216       negative  0.626
    988036       negative  0.624
    3073009      negative  0.623
    316969       negative  0.622
    263169       negative  0.622
    1915456      negative  0.618
    221841       negative  0.614
    846400       negative  0.612
    350464       negative  0.611
    199809       negative  0.610
    40804        negative  0.609
    4691556      negative  0.609
    984064       negative  0.608
    824464       negative  0.606
    848241       negative  0.600
    36481        negative  0.598
    38025        negative  0.598
    41209        negative  0.598
    4652649      negative  0.598
    4661281      negative  0.598
    4695889      negative  0.598
    839056       negative  0.595
    822649       negative  0.589
    3422500      negative  0.569
    833569       negative  0.566
    850084       negative  0.565
    3182656      negative  0.535
    819025       negative  0.533
    3323329      positive  0.518

    [2397 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.894, ROC-AUC = 0.999, recall @20%: 1.000 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 340844aa3c524190
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/340844aa3c524190
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/340844aa3c524190/predict
                 category  nearest_document_id  score
    document_id                                      
    5041         negative               150544  1.000
    5625         negative               150544  1.000
    27556        negative               150544  1.000
    29241        negative               150544  1.000
    30625        negative               150544  1.000
    35721        negative               150544  1.000
    37249        negative               150544  1.000
    75076        negative               150544  1.000
    112225       negative               150544  1.000
    138384       negative               150544  1.000
    153664       negative               150544  1.000
    159201       negative               150544  1.000
    164836       negative               150544  1.000
    197136       negative               150544  1.000
    200704       negative               150544  1.000
    205209       negative               150544  1.000
    230400       negative               150544  1.000
    329476       negative               150544  1.000
    354025       negative               150544  1.000
    381924       negative               150544  1.000
    432964       negative               150544  1.000
    465124       negative               150544  1.000
    531441       negative               150544  1.000
    541696       negative               150544  1.000
    588289       negative               150544  1.000
    606841       negative               150544  1.000
    620944       negative               150544  1.000
    643204       negative               150544  1.000
    652864       negative              1555009  1.000
    656100       negative               150544  1.000
    ...               ...                  ...    ...
    692224       negative              2042041  0.299
    206116       negative               633616  0.298
    5914624      negative               974169  0.298
    1592644      negative              1218816  0.298
    160801       negative              4575321  0.297
    5924356      negative              4575321  0.297
    207936       negative              2560000  0.297
    720801       negative               908209  0.296
    769129       positive               844561  0.294
    363609       negative                 9801  0.294
    161604       negative                 6561  0.291
    1747684      negative               456976  0.291
    463761       negative               335241  0.288
    487204       negative                 9025  0.287
    300304       negative               498436  0.285
    490000       negative                 9025  0.285
    484416       negative              4272489  0.284
    5929225      negative                 9025  0.282
    1155625      negative              1218816  0.279
    1159929      negative              1218816  0.279
    1164241      negative              1218816  0.279
    3481956      negative              1218816  0.279
    3489424      negative              1218816  0.279
    519841       negative              4498641  0.274
    504100       negative              4575321  0.270
    524176       negative              4575321  0.269
    543169       negative              2442969  0.268
    544644       positive               844561  0.268
    361201       positive              3207681  0.266
    546121       positive              3207681  0.266

    [2397 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.342, ROC-AUC = 0.653, recall @20%: 0.571 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/e471fdfa0237449e




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])} \
                                       for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'dataset_definition': dataset_definition,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(pd.DataFrame(input_ds['training_set'])\
                                 .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)


            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                          'y_pred': res['data'] }).json()


            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  19.591 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
