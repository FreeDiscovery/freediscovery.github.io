

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['id']
       => dsid = 32ab863189bc4463

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/32ab863189bc4463

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/32ab863189bc4463

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/32ab863189bc4463
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: /home/ubuntu/freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - parse_email_headers: False
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: False
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = 8dc367cb8ee9499f
      => SVD decomposition with 100 dimensions explaining 76.43 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 14c14f92f8044165
        => Training scores: MAP = 0.907, ROC-AUC = 0.900, recall @20%: 0.800 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/14c14f92f8044165
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/14c14f92f8044165/predict
                 category  score
    document_id                 
    454276       negative  0.775
    568516       negative  0.775
    1803649      negative  0.764
    2845969      negative  0.764
    573049       negative  0.763
    319225       negative  0.762
    1723969      negative  0.761
    3290596      negative  0.761
    3326976      negative  0.761
    3243601      negative  0.760
    806404       negative  0.760
    4405801      negative  0.760
    1098304      negative  0.760
    600625       negative  0.759
    3225616      negative  0.759
    3496900      negative  0.758
    877969       negative  0.758
    885481       negative  0.758
    118336       negative  0.757
    1077444      negative  0.757
    10000        negative  0.757
    3545689      negative  0.757
    3636649      negative  0.756
    1557504      negative  0.756
    5230369      negative  0.756
    1285956      negative  0.756
    106929       negative  0.755
    1052676      negative  0.755
    258064       negative  0.755
    654481       negative  0.755
    ...               ...    ...
    229441       negative  0.627
    817216       negative  0.627
    988036       negative  0.625
    3073009      negative  0.623
    316969       negative  0.622
    263169       negative  0.622
    1915456      negative  0.618
    221841       negative  0.614
    846400       negative  0.612
    350464       negative  0.611
    199809       negative  0.610
    40804        negative  0.609
    4691556      negative  0.609
    984064       negative  0.609
    824464       negative  0.606
    848241       negative  0.601
    36481        negative  0.598
    4695889      negative  0.598
    4661281      negative  0.598
    38025        negative  0.598
    4652649      negative  0.598
    41209        negative  0.598
    839056       negative  0.595
    822649       negative  0.589
    3422500      negative  0.569
    833569       negative  0.567
    850084       negative  0.566
    3182656      negative  0.535
    819025       negative  0.533
    3323329      positive  0.518

    [2397 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.894, ROC-AUC = 0.999, recall @20%: 1.000 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 0285cbb2dd064b6c
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/0285cbb2dd064b6c
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/0285cbb2dd064b6c/predict
                 category  nearest_document_id  score
    document_id                                      
    112225       negative               150544  1.000
    5625         negative               150544  1.000
    75076        negative               150544  1.000
    531441       negative               150544  1.000
    381924       negative               150544  1.000
    1087849      negative               150544  1.000
    432964       negative               150544  1.000
    1102500      negative               150544  1.000
    678976       negative               150544  1.000
    1115136      negative               150544  1.000
    35721        negative               150544  1.000
    1177225      negative               150544  1.000
    588289       negative               150544  1.000
    138384       negative               150544  1.000
    1203409      negative               150544  1.000
    1210000      negative              1218816  1.000
    620944       negative               150544  1.000
    73984        negative                75625  1.000
    1067089      negative               150544  1.000
    925444       negative               150544  1.000
    54756        negative                75625  1.000
    29241        negative               150544  1.000
    3617604      negative              1218816  1.000
    37249        negative               150544  1.000
    727609       negative               150544  1.000
    354025       negative               150544  1.000
    27556        negative               150544  1.000
    329476       negative               150544  1.000
    3625216      negative              1218816  1.000
    748225       negative               150544  1.000
    ...               ...                  ...    ...
    763876       negative              4963984  0.133
    1779556      negative              4498641  0.131
    5924356      negative               974169  0.128
    160801       negative               974169  0.128
    309136       negative              4260096  0.127
    206116       negative               456976  0.122
    287296       negative              2788900  0.116
    285156       negative              2788900  0.116
    161604       negative                 6561  0.114
    5143824      negative              2076481  0.112
    1747684      negative               456976  0.111
    5929225      negative                 9025  0.104
    363609       negative                 9801  0.098
    300304       negative              1787569  0.097
    484416       negative              4272489  0.096
    463761       negative               938961  0.093
    487204       negative                   81  0.079
    3481956      positive              1096209  0.072
    1159929      positive              1096209  0.072
    3489424      positive              1096209  0.072
    1155625      positive              1096209  0.072
    1164241      positive              1096209  0.072
    490000       negative                   81  0.063
    519841       negative              4498641  0.060
    544644       positive               844561  0.052
    543169       negative              2442969  0.050
    524176       negative              4575321  0.041
    361201       negative               225625  0.040
    546121       negative               225625  0.040
    504100       negative              4575321  0.036

    [2397 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.341, ROC-AUC = 0.648, recall @20%: 0.571 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/32ab863189bc4463




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])}
                              for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,),
                    kwargs={'json': {'dataset_definition': dataset_definition}})
        p.start()
        sleep(5.0)  # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break  # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000,
                        (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary

        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val)
              for key, val in res.items() if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))

        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(
              pd.DataFrame(input_ds['training_set'])
                .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val)
                  for key, val in res.items() if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url, json={'subset': 'test'}).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)

            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                           'y_pred': res['data']}).json()

            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  9.613 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
