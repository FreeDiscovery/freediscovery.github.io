

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['filenames', 'id']
       => dsid = 905d37841c304f05

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/905d37841c304f05

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/905d37841c304f05

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/905d37841c304f05
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: True
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = 803b9daf95724680
      => SVD decomposition with 100 dimensions explaining 76.50 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = edf6693e92fc4d84
        => Training scores: MAP = 0.907, ROC-AUC = 0.900, recall @20%: 0.800 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/edf6693e92fc4d84
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/edf6693e92fc4d84/predict
                 category  score
    document_id                 
    0            negative  0.641
    1            negative  0.697
    4            negative  0.675
    9            negative  0.549
    16           negative  0.665
    25           negative  0.666
    36           negative  0.680
    49           negative  0.678
    64           negative  0.667
    81           negative  0.695
    100          negative  0.659
    121          negative  0.740
    144          negative  0.730
    169          negative  0.718
    196          negative  0.722
    225          negative  0.694
    256          negative  0.738
    289          negative  0.739
    324          negative  0.707
    361          negative  0.745
    400          negative  0.696
    441          negative  0.723
    484          negative  0.743
    529          negative  0.731
    576          negative  0.707
    625          negative  0.732
    676          negative  0.737
    729          negative  0.729
    784          negative  0.739
    841          negative  0.740
    ...               ...    ...
    5929225      negative  0.750
    5934096      negative  0.681
    5938969      negative  0.706
    5943844      negative  0.704
    5948721      negative  0.695
    5953600      negative  0.718
    5958481      negative  0.689
    5963364      negative  0.715
    5968249      negative  0.658
    5973136      negative  0.684
    5978025      negative  0.678
    5982916      negative  0.704
    5987809      negative  0.658
    5992704      negative  0.682
    5997601      negative  0.670
    6002500      negative  0.701
    6007401      negative  0.688
    6012304      negative  0.710
    6017209      negative  0.664
    6022116      negative  0.686
    6027025      negative  0.695
    6031936      negative  0.646
    6036849      negative  0.706
    6041764      negative  0.659
    6046681      negative  0.691
    6051600      negative  0.684
    6056521      negative  0.683
    6061444      negative  0.725
    6066369      negative  0.680
    6071296      negative  0.714

    [2465 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.948, ROC-AUC = 0.999, recall @20%: 1.000 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = f00ea903ac8540f0
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/f00ea903ac8540f0
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/f00ea903ac8540f0/predict
                 category  nearest_document_id  score
    document_id                                      
    0            negative              2560000  0.408
    1            negative               225625  0.337
    4            negative              3048516  0.406
    9            positive                    9  1.000
    16           positive                    9  0.607
    25           negative              2442969  0.341
    36           negative              2560000  0.508
    49           negative              1449616  0.404
    64           negative                   81  0.433
    81           negative                   81  1.000
    100          positive                    9  0.486
    121          negative                 1024  0.349
    144          negative                 1024  0.337
    169          negative              4157521  0.374
    196          negative              4157521  0.985
    225          negative              2442969  0.414
    256          negative                 1024  0.373
    289          negative              3632836  0.328
    324          negative                   81  0.331
    361          negative              1218816  0.457
    400          negative              6007401  0.439
    441          negative              5175625  0.726
    484          negative              3254416  0.329
    529          negative              3254416  0.325
    576          negative              4498641  0.388
    625          negative              5175625  0.482
    676          negative                 1024  0.320
    729          negative               131044  0.368
    784          negative                 1024  0.363
    841          negative              3632836  0.323
    ...               ...                  ...    ...
    5929225      negative              2050624  0.288
    5934096      negative               378225  0.544
    5938969      negative               378225  0.408
    5943844      negative              1449616  0.360
    5948721      negative              1247689  0.385
    5953600      negative              1247689  0.362
    5958481      negative              2259009  0.416
    5963364      negative               131044  0.343
    5968249      negative                   81  0.402
    5973136      negative                   81  0.328
    5978025      negative                   81  0.426
    5982916      negative                   81  0.342
    5987809      negative              5354596  0.430
    5992704      positive              1096209  0.320
    5997601      negative               378225  0.492
    6002500      negative              5697769  0.662
    6007401      negative              6007401  1.000
    6012304      negative              6007401  0.700
    6017209      negative              1787569  0.491
    6022116      negative              1787569  0.412
    6027025      positive                    9  0.489
    6031936      positive                    9  0.745
    6036849      negative              2442969  0.498
    6041764      negative               378225  0.339
    6046681      negative              2076481  0.709
    6051600      negative              2076481  0.343
    6056521      negative                 6561  0.301
    6061444      negative              2076481  0.345
    6066369      positive               844561  0.316
    6071296      negative              2076481  0.428

    [2465 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.649, ROC-AUC = 0.802, recall @20%: 0.750 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/905d37841c304f05




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])} \
                                       for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'dataset_definition': dataset_definition,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(pd.DataFrame(input_ds['training_set'])\
                                 .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)


            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                          'y_pred': res['data'] }).json()


            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  17.694 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
