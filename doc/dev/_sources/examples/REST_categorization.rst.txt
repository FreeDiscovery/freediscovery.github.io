

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the test dataset
     GET http://localhost:5001/api/v0/datasets/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received [u'id', u'filenames']
       => dsid = 161613e720a142b7

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/161613e720a142b7

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/161613e720a142b7

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/161613e720a142b7
         - binary: False
         - n_jobs: 1
         - stop_words: None
         - use_hashing: True
         - min_df: 0.0
         - n_samples: 2465
         - analyzer: word
         - ngram_range: [1, 1]
         - max_df: 1.0
         - chunk_size: 5000
         - use_idf: False
         - data_dir: ../freediscovery_shared/treclegal09_2k_subset/data
         - sublinear_tf: True
         - n_samples_processed: 2465
         - n_features: 100001
         - norm: None

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = b6987875a1664701
      => SVD decomposition with 100 dimensions explaining 99.79 % variabilty of the data

    3.a. Train the categorization model
       5 relevant, 63 non-relevant files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = ade69becc0c648b9
        => Training scores: MAP = 0.537, ROC-AUC = nan

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/ade69becc0c648b9
         - method: LinearSVC
         - options: {'loss': 'squared_hinge', 'C': 1.0, 'verbose': 0, 'intercept_scaling': 1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'multi_class': 'ovr', 'random_state': None, 'dual': True, 'tol': 0.0001, 'class_weight': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/ade69becc0c648b9/predict
                 score
    internal_id       
    0           -0.846
    1           -0.846
    2           -0.846
    3           -0.846
    4           -0.846
    5           -0.846
    6           -0.846
    7           -0.846
    8           -0.846
    9           -0.846
    10          -0.846
    11          -0.846
    12          -0.846
    13          -0.847
    14          -0.846
    15          -0.846
    16          -0.847
    17          -0.846
    18          -0.846
    19          -0.846
    20          -0.846
    21          -0.847
    22          -0.846
    23          -0.846
    24          -0.846
    25          -0.847
    26          -0.846
    27          -0.846
    28          -0.847
    29          -0.846
    ...            ...
    2435        -0.849
    2436        -0.846
    2437        -0.846
    2438        -0.846
    2439        -0.846
    2440        -0.846
    2441        -0.846
    2442        -0.846
    2443        -0.846
    2444        -0.846
    2445        -0.846
    2446        -0.846
    2447        -0.846
    2448        -0.846
    2449        -0.846
    2450        -0.846
    2451        -0.846
    2452        -0.846
    2453        -0.846
    2454        -0.846
    2455        -0.846
    2456        -0.846
    2457        -0.846
    2458        -0.846
    2459        -0.846
    2460        -0.846
    2461        -0.846
    2462        -0.846
    2463        -0.846
    2464        -0.846

    [2465 rows x 1 columns]

    3.d Test categorization accuracy
             using ../freediscovery_shared/treclegal09_2k_subset/ground_truth_file.txt
    POST http://localhost:5001/api/v0/categorization/ade69becc0c648b9/test
        => Test scores: MAP = 0.502, ROC-AUC = nan
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = a40ec92c135f49f6
        => Training scores: MAP = 1.000, ROC-AUC = 1.000

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/a40ec92c135f49f6
         - method: NearestNeighbor
         - options: {'ranking': None, 'n_jobs': None, 'radius': None, 'leaf_size': None, 'algorithm': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/a40ec92c135f49f6/predict
                 nn_negative__distance  nn_negative__internal_id  nn_positive__distance  nn_positive__internal_id  score
    internal_id                                                                                                         
    0                            0.224                        52                  0.211                         3  0.895
    1                            0.583                        18                  0.660                         4 -0.708
    2                            0.087                        21                  0.084                         0  0.958
    3                            0.061                        21                  0.000                         0  1.000
    4                            0.121                        21                  0.115                         0  0.942
    5                            0.107                        21                  0.092                         0  0.954
    6                            0.128                        21                  0.106                         0  0.947
    7                            0.096                        21                  0.070                         0  0.965
    8                            0.091                        37                  0.087                         0  0.957
    9                            0.000                         5                  0.106                         0 -1.000
    10                           0.088                        21                  0.048                         0  0.976
    11                           0.570                        58                  0.679                         4 -0.715
    12                           0.576                        58                  0.660                         4 -0.712
    13                           0.578                        55                  0.656                         3 -0.711
    14                           0.082                        55                  0.606                         4 -0.959
    15                           0.223                        12                  0.431                         1 -0.888
    16                           0.653                        58                  0.704                         4 -0.673
    17                           0.625                        58                  0.669                         4 -0.687
    18                           0.429                        12                  0.551                         1 -0.786
    19                           0.402                        12                  0.610                         1 -0.799
    20                           0.211                        12                  0.459                         1 -0.895
    21                           0.364                        63                  0.674                         3 -0.818
    22                           0.549                        53                  0.650                         4 -0.725
    23                           0.540                        53                  0.650                         4 -0.730
    24                           0.396                        12                  0.542                         4 -0.802
    25                           0.597                        63                  0.714                         4 -0.702
    26                           0.602                        58                  0.689                         4 -0.699
    27                           0.489                        26                  0.602                         2 -0.755
    28                           0.650                        58                  0.707                         4 -0.675
    29                           0.626                        58                  0.673                         4 -0.687
    ...                            ...                       ...                    ...                       ...    ...
    2435                         0.648                        59                  0.682                         0 -0.676
    2436                         0.112                        21                  0.101                         0  0.950
    2437                         0.215                        47                  0.358                         1 -0.893
    2438                         0.205                        47                  0.318                         0 -0.898
    2439                         0.096                         5                  0.105                         0 -0.952
    2440                         0.187                        47                  0.324                         0 -0.906
    2441                         0.092                         5                  0.100                         0 -0.954
    2442                         0.192                        47                  0.314                         0 -0.904
    2443                         0.127                        52                  0.124                         0  0.938
    2444                         0.239                        47                  0.345                         4 -0.880
    2445                         0.141                        37                  0.131                         0  0.935
    2446                         0.220                        35                  0.348                         0 -0.890
    2447                         0.111                        64                  0.096                         0  0.952
    2448                         0.173                        66                  0.329                         1 -0.913
    2449                         0.090                        21                  0.054                         0  0.973
    2450                         0.198                        66                  0.301                         0 -0.901
    2451                         0.000                        67                  0.124                         0 -1.000
    2452                         0.233                        47                  0.339                         0 -0.884
    2453                         0.144                        51                  0.200                         0 -0.928
    2454                         0.283                        47                  0.337                         1 -0.858
    2455                         0.138                        47                  0.327                         0 -0.931
    2456                         0.055                        21                  0.034                         0  0.983
    2457                         0.217                        47                  0.322                         0 -0.892
    2458                         0.112                        21                  0.090                         0  0.955
    2459                         0.196                        42                  0.539                         2 -0.902
    2460                         0.418                        42                  0.520                         3 -0.791
    2461                         0.461                        13                  0.505                         2 -0.769
    2462                         0.434                        39                  0.619                         0 -0.783
    2463                         0.471                        39                  0.542                         2 -0.764
    2464                         0.425                        42                  0.549                         0 -0.787

    [2465 rows x 5 columns]

    3.d Test categorization accuracy
             using ../freediscovery_shared/treclegal09_2k_subset/ground_truth_file.txt
    POST http://localhost:5001/api/v0/categorization/a40ec92c135f49f6/test
        => Test scores: MAP = 0.355, ROC-AUC = 0.796

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/161613e720a142b7




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the test dataset")
        url = BASE_URL + '/datasets/{}'.format(dataset_name)
        print(" GET", url)
        res = requests.get(url).json()

        # To use a custom dataset, simply specify the following variables
        data_dir = res['data_dir']
        seed_filenames = res['seed_filenames']
        seed_y = res['seed_y']
        ground_truth_file = res['ground_truth_file']  # (optional)


        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url, json={'data_dir': data_dir,
                                       'use_hashing': True}).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,))
        p.start()
        sleep(5.0) # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000, (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary


        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                          if "filenames" not in key]))

        method = BASE_URL + "/feature-extraction/{}/index".format(dsid)
        res = requests.get(method, data={'filenames': seed_filenames})
        seed_index = res.json()['index']


        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))


        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} relevant, {} non-relevant files".format(seed_y.count(1), seed_y.count(0)))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'index': seed_index,
                                      'y': seed_y,
                                      'parent_id': parent_id,
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}'.format(**res))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items() \
                                                              if key not in ['index', 'y']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            if method == "NearestNeighbor":

                def flatten_dict(d, parent_key='', sep='__'):
                    """Flatten a nested dictionary """
                    import collections
                    items = []
                    for k, v in d.items():
                        new_key = parent_key + sep + k if parent_key else k
                        if isinstance(v, collections.MutableMapping):
                            items.extend(flatten_dict(v, new_key, sep=sep).items())
                        else:
                            items.append((new_key, v))
                    return dict(items)
            
                data = [flatten_dict(el) for el in res['data']]
            else:
                data = res['data']

            print(pd.DataFrame(data).set_index('internal_id'))

            print("\n3.d Test categorization accuracy")
            print("         using {}".format(ground_truth_file))  
            url = BASE_URL + '/categorization/{}/test'.format(mid)
            print("POST", url)
            res = requests.post(url, json={'ground_truth_filename': ground_truth_file}).json()

            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}'.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 1 minutes  1.746 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
