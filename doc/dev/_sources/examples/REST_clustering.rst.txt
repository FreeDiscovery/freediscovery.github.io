

.. _sphx_glr_examples_REST_clustering.py:


Clustering Example [REST API]
-----------------------------

Cluster documents into clusters





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['id']
       => dsid = f072e254a5d74023

    1.b Run feature extraction
     POST http://localhost:5001/api/v0/feature-extraction/f072e254a5d74023

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/f072e254a5d74023
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: /home/ubuntu/freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - parse_email_headers: False
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: False
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = a7aec4e5a9494291
      => SVD decomposition with 300 dimensions explaining 90.00 % variabilty of the data

    3.a. Document clustering (LSI + K-means)
     POST http://localhost:5001/api/v0/clustering/k-mean/
         => model id = 2d7549f8ac94487d

    3.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/k-mean/2d7549f8ac94487d
        .. computed in 1.3s
       cluster_id                    cluster_label  cluster_similarity  cluster_size  n_documents
    0           0  enron_development issues brazil               0.188           201          201
    1           1                   thu normal nov               0.093           798          798
    2           2            test group recipients               0.274           142          142
    3           3                 mon normal tenet               0.210           252          252
    4           4               shall party lessee               0.257           177          177
    5           5                 wed enron normal               0.126           449          449
    6           6          conference normal teneo               0.287           159          159
    7           7                   ect hou advice               0.414            81           81
    8           8           rewrite address server               1.000            56           56
    9           9                   tue normal oct               0.253           150          150

    4.a. Document clustering (LSI + Birch clustering)
     POST http://localhost:5001/api/v0/clustering/birch/
         => model id = 55e01c2f97a9421b

    4.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/birch/55e01c2f97a9421b
        .. computed in 2.2s
                                                 children  cluster_depth  cluster_id                          cluster_label  cluster_similarity  cluster_size  n_documents
    0   [1, 3, 5, 7, 15, 19, 21, 23, 26, 41, 43, 46, 5...              0           0                        normal test ect               0.071          2465         2465
    1                                                 [2]              1           1                 rewrite address server               0.875            63           63
    2                                                  []              2           2                 rewrite address server               0.875            63           63
    3                                                 [4]              1           3                laryngitis speak severe               0.634             6            6
    4                                                  []              2           4                laryngitis speak severe               0.634             6            6
    5                                                 [6]              1           5                  cini deseret etringer               0.502            19           19
    6                                                  []              2           6                  cini deseret etringer               0.502            19           19
    7                          [8, 9, 10, 11, 12, 13, 14]              1           7      shackleton enron_development test               0.172           263          263
    8                                                  []              2           8          enron_development issues cone               0.377            49           49
    9                                                  []              2           9             credit counterparty change               0.397            27           27
    10                                                 []              2          10     enron_development advice committee               0.389            53           53
    11                                                 []              2          11                  calo shackleton dupre               0.316            51           51
    12                                                 []              2          12                  attorney tiger brazil               0.356            37           37
    13                                                 []              2          13                  shackleton class test               0.459            18           18
    14                                                 []              2          14      shackleton shackleton_sara normal               0.489            28           28
    15                                       [16, 17, 18]              1          15                      teneo normal load               0.448            79           79
    16                                                 []              2          16                   sellers language thu               0.789             2            2
    17                                                 []              2          17                       teneo normal fri               0.503            53           53
    18                                                 []              2          18                        load meet teneo               0.487            24           24
    19                                               [20]              1          19                      memo marcelo mail               0.522            13           13
    20                                                 []              2          20                      memo marcelo mail               0.522            13           13
    21                                               [22]              1          21                           ena swap rmt               0.537            20           20
    22                                                 []              2          22                           ena swap rmt               0.537            20           20
    23                                           [24, 25]              1          23                          ect hou bowen               0.326           104          104
    24                                                 []              2          24                          ect hou ellis               0.437            71           71
    25                                                 []              2          25                       bowen murray ect               0.326            33           33
    26  [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 3...              1          26              group test administrative               0.131           457          457
    27                                                 []              2          27                  customer shall energy               0.349            59           59
    28                                                 []              2          28                  test teneo recipients               0.340            57           57
    29                                                 []              2          29                   mtg tozzini november               0.432            25           25
    ..                                                ...            ...         ...                                    ...                 ...           ...          ...
    65                                                 []              2          65                  language think issues               0.319            28           28
    66                                                 []              2          66                   davis shults masters               0.384            27           27
    67                                                 []              2          67  sager americancentury sager_elizabeth               0.331            38           38
    68                                                 []              2          68                    haedicke normal mtg               0.372            37           37
    69                                                 []              2          69                      dead horse master               0.415            24           24
    70                                                 []              2          70                         fri nov normal               0.298            29           29
    71                                                 []              2          71                      mtg ruppert exxon               0.302            52           52
    72                                                 []              2          72                          wed oct tenet               0.412            37           37
    73                                                 []              2          73                       thu tenet office               0.382            33           33
    74                                           [75, 76]              1          74                 meet eb3325 ricafrente               0.372            74           74
    75                                                 []              2          75                        meet eb3325 tue               0.396            38           38
    76                                                 []              2          76                    meet eb3325 finance               0.447            36           36
    77  [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 8...              1          77                       tenet normal mon               0.139           458          458
    78                                                 []              2          78                jones tana presentation               0.373            29           29
    79                                                 []              2          79                   enrononline new plan               0.349            28           28
    80                                                 []              2          80                       canada isda poon               0.324            32           32
    81                                                 []              2          81                     trading jones tana               0.356            30           30
    82                                                 []              2          82                      deal aquilla muni               0.433            28           28
    83                                                 []              2          83                          mon tenet nov               0.393            37           37
    84                                                 []              2          84                         mon clair room               0.481            10           10
    85                                                 []              2          85                   kincannon oct normal               0.437            16           16
    86                                                 []              2          86           performance management tiger               0.278            46           46
    87                                                 []              2          87                          mtg enron gtc               0.322            32           32
    88                                                 []              2          88                        budget fri room               0.368            35           35
    89                                                 []              2          89                          fri tenet oct               0.457            27           27
    90                                                 []              2          90                       mon tenet normal               0.359            48           48
    91                                                 []              2          91                     office tue meeting               0.376            35           35
    92                                                 []              2          92                          tue tenet oct               0.485            25           25
    93                                               [94]              1          93                awais final description               0.469            21           21
    94                                                 []              2          94                awais final description               0.469            21           21

    [95 rows x 7 columns]

    4.a. Optimal sampling (LSI + Birch clustering)
     GET http://localhost:5001/api/v0/clustering/birch/55e01c2f97a9421b
        .. computed in 0.1s
        cluster_id  cluster_similarity  cluster_size                                          documents
    0           55               0.357            80  [{'document_id': 168921, 'similarity': 0.81068...
    1           24               0.437            71  [{'document_id': 11236, 'similarity': 0.804485...
    2           48               0.399            68  [{'document_id': 293764, 'similarity': 0.74846...
    3            2               0.875            63  [{'document_id': 5625, 'similarity': 0.9973185...
    4           27               0.349            59  [{'document_id': 682276, 'similarity': 0.63286...
    5           28               0.340            57  [{'document_id': 3418801, 'similarity': 0.6820...
    6           10               0.389            53  [{'document_id': 33124, 'similarity': 0.601959...
    7           17               0.503            53  [{'document_id': 314721, 'similarity': 0.68276...
    8           71               0.302            52  [{'document_id': 5480281, 'similarity': 0.5567...
    9           11               0.316            51  [{'document_id': 1306449, 'similarity': 0.6022...
    10           8               0.377            49  [{'document_id': 131769, 'similarity': 0.75942...
    11          90               0.359            48  [{'document_id': 2169729, 'similarity': 0.6959...
    12          54               0.406            47  [{'document_id': 97969, 'similarity': 0.611499...
    13          86               0.278            46  [{'document_id': 390625, 'similarity': 0.44800...
    14          37               0.333            45  [{'document_id': 4624, 'similarity': 0.7863429...
    15          49               0.406            40  [{'document_id': 1117249, 'similarity': 0.5306...
    16          36               0.400            38  [{'document_id': 1098304, 'similarity': 0.6205...
    17          67               0.331            38  [{'document_id': 992016, 'similarity': 0.59899...
    18          75               0.396            38  [{'document_id': 2461761, 'similarity': 0.5946...
    19          12               0.356            37  [{'document_id': 36481, 'similarity': 0.505836...
    20          44               0.325            37  [{'document_id': 160801, 'similarity': 0.64793...
    21          68               0.372            37  [{'document_id': 3470769, 'similarity': 0.5169...
    22          72               0.412            37  [{'document_id': 3455881, 'similarity': 0.7181...
    23          83               0.393            37  [{'document_id': 6041764, 'similarity': 0.6343...
    24          56               0.342            36  [{'document_id': 14884, 'similarity': 0.505767...
    25          76               0.447            36  [{'document_id': 2582449, 'similarity': 0.6078...
    26          88               0.368            35  [{'document_id': 2359296, 'similarity': 0.5925...
    27          91               0.376            35  [{'document_id': 3171961, 'similarity': 0.7399...
    28          33               0.367            34  [{'document_id': 749956, 'similarity': 0.55272...
    29          25               0.326            33  [{'document_id': 1263376, 'similarity': 0.5383...
    30          73               0.382            33  [{'document_id': 2325625, 'similarity': 0.6587...
    31          31               0.343            32  [{'document_id': 583696, 'similarity': 0.56926...
    32          40               0.485            32  [{'document_id': 154449, 'similarity': 0.89989...
    33          62               0.323            32  [{'document_id': 2893401, 'similarity': 0.6008...
    34          80               0.324            32  [{'document_id': 1155625, 'similarity': 0.4803...
    35          87               0.322            32  [{'document_id': 5560164, 'similarity': 0.5358...
    36          34               0.323            31  [{'document_id': 906304, 'similarity': 0.57869...
    37          50               0.436            31  [{'document_id': 3980025, 'similarity': 0.6617...
    38          57               0.332            31  [{'document_id': 94249, 'similarity': 0.555554...
    39          81               0.356            30  [{'document_id': 2117025, 'similarity': 0.5074...
    40          70               0.298            29  [{'document_id': 2356225, 'similarity': 0.5118...
    41          78               0.373            29  [{'document_id': 275625, 'similarity': 0.59841...
    42          14               0.489            28  [{'document_id': 61504, 'similarity': 0.604281...
    43          65               0.319            28  [{'document_id': 1216609, 'similarity': 0.5763...
    44          79               0.349            28  [{'document_id': 2073600, 'similarity': 0.5243...
    45          82               0.433            28  [{'document_id': 7396, 'similarity': 0.8069986...
    46           9               0.397            27  [{'document_id': 7569, 'similarity': 0.6148384...
    47          47               0.367            27  [{'document_id': 33856, 'similarity': 0.505749...
    48          66               0.384            27  [{'document_id': 1157776, 'similarity': 0.6306...
    49          89               0.457            27  [{'document_id': 2468041, 'similarity': 0.7531...
    50          35               0.355            26  [{'document_id': 866761, 'similarity': 0.54115...
    51          38               0.374            26  [{'document_id': 1597696, 'similarity': 0.7351...
    52          61               0.415            26  [{'document_id': 1234321, 'similarity': 0.7258...
    53          64               0.341            26  [{'document_id': 1442401, 'similarity': 0.6074...
    54          29               0.432            25  [{'document_id': 120409, 'similarity': 0.71765...
    55          63               0.419            25  [{'document_id': 3587236, 'similarity': 0.5875...
    56          92               0.485            25  [{'document_id': 1893376, 'similarity': 0.7736...
    57          18               0.487            24  [{'document_id': 290521, 'similarity': 0.66932...
    58          69               0.415            24  [{'document_id': 1060900, 'similarity': 0.6434...
    59          94               0.469            21  [{'document_id': 207936, 'similarity': 0.70322...

    5. Delete the extracted features
     DELETE http://localhost:5001/api/v0/feature-extraction/f072e254a5d74023




|


.. code-block:: python


    import os.path
    import pandas as pd
    from time import time
    import requests

    pd.options.display.float_format = '{:,.3f}'.format


    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    print(" 0. Load the example dataset")
    url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
    print(" GET", url)
    input_ds = requests.get(url).json()

    # To use a custom dataset, simply specify the following variables
    data_dir = input_ds['metadata']['data_dir']
    dataset_definition = [{'document_id': row['document_id'],
                           'file_path': os.path.join(data_dir, row['file_path'])}
                          for row in input_ds['dataset']]

    # # 1. Feature extraction (non hashed)

    print("\n1.a Load dataset and initalize feature extraction")
    url = BASE_URL + '/feature-extraction'
    print(" POST", url)
    fe_opts = {  # 'min_df': 4, 'max_df': 0.75  # filter out (too)/(un)frequent words
               }
    res = requests.post(url, json=fe_opts).json()

    dsid = res['id']
    print("   => received {}".format(list(res.keys())))
    print("   => dsid = {}".format(dsid))


    print("\n1.b Run feature extraction")
    # progress status is available for the hashed version only
    url = BASE_URL+'/feature-extraction/{}'.format(dsid)
    print(" POST", url)
    res = requests.post(url, json={'dataset_definition': dataset_definition})

    print("\n1.d. check the parameters of the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(' GET', url)
    res = requests.get(url).json()

    print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items()
                     if "filenames" not in key]))

    print("\n2. Calculate LSI")

    url = BASE_URL + '/lsi/'
    print("POST", url)

    n_components = 300
    res = requests.post(url,
                        json={'n_components': n_components,
                              'parent_id': dsid
                              }).json()

    lsi_id = res['id']
    print('  => LSI model id = {}'.format(lsi_id))
    print(('  => SVD decomposition with {} dimensions '
           'explaining {:.2f} % variabilty of the data')
          .format(n_components, res['explained_variance']*100))

    # # 3. Document Clustering (LSI + K-Means)

    print("\n3.a. Document clustering (LSI + K-means)")

    url = BASE_URL + '/clustering/k-mean/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': 10,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n3.b. Computing cluster labels")
    url = BASE_URL + '/clustering/k-mean/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()


    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    print(pd.DataFrame(data))


    # # 4. Document Clustering (LSI + Birch Clustering)

    print("\n4.a. Document clustering (LSI + Birch clustering)")

    url = BASE_URL + '/clustering/birch/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': -1,
                              'min_similarity': 0.7,
                              'branching_factor': 20,
                              'max_tree_depth': 2,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n4.b. Computing cluster labels")
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print(pd.DataFrame(data))

    # # 4. Optimal sampling (LSI + Birch Clustering)

    print("\n4.a. Optimal sampling (LSI + Birch clustering)")

    t0 = time()
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'return_optimal_sampling': True,
                             'sampling_min_coverage': 0.9
                             }).json()
    t1 = time()
    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']

    print(pd.DataFrame(data))

    # 4. Cleaning
    print("\n5. Delete the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(" DELETE", url)
    requests.delete(url)

**Total running time of the script:** ( 0 minutes  11.201 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_clustering.py <REST_clustering.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_clustering.ipynb <REST_clustering.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
