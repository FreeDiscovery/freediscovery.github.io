

.. _sphx_glr_examples_REST_clustering.py:


Clustering Example [REST API]
-----------------------------

Cluster documents into clusters





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['id']
       => dsid = ef60bf5a05214071

    1.b Run feature extraction
     POST http://localhost:5001/api/v0/feature-extraction/ef60bf5a05214071

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/ef60bf5a05214071
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: /home/ubuntu/freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - parse_email_headers: False
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: False
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = 9e1752278ef24c49
      => SVD decomposition with 300 dimensions explaining 90.00 % variabilty of the data

    3.a. Document clustering (LSI + K-means)
     POST http://localhost:5001/api/v0/clustering/k-mean/
         => model id = 31f57a87274142df

    3.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/k-mean/31f57a87274142df
        .. computed in 1.2s
       cluster_id                    cluster_label  cluster_similarity  cluster_size  n_documents
    0           0               subject doc normal               0.078           969          969
    1           1                 enron jones tana               0.143           297          297
    2           2                wed budget normal               0.243           147          147
    3           3         shall agreement services               0.418            87           87
    4           4                 normal tenet mon               0.216           265          265
    5           5                  tue meet normal               0.285           126          126
    6           6  ricafrente ricafrente_david nov               0.282           135          135
    7           7           rewrite address server               1.000            56           56
    8           8   test recipients administrative               0.278           164          164
    9           9                  ect hou meeting               0.202           219          219

    4.a. Document clustering (LSI + Birch clustering)
     POST http://localhost:5001/api/v0/clustering/birch/
         => model id = 23322e00eee34406

    4.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/birch/23322e00eee34406
        .. computed in 2.2s
                                                 children  cluster_depth  cluster_id                    cluster_label  cluster_similarity  cluster_size  n_documents
    0                                              [1, 4]              0           0                  normal test ect               0.071          2465         2465
    1                                                 [2]              1           1           rewrite address server               0.950            59           59
    2                                                  []              2           2           rewrite address server               0.950            59           59
    3   [5, 14, 16, 19, 21, 23, 31, 33, 36, 38, 43, 64...              1           4                  normal test ect               0.068          2406         2406
    4                                                  []              2           5  shackleton shackleton_sara cone               0.179           238          238
    5                                                  []              2          14              guaranty tiger muni               0.618            16           16
    6                                                  []              2          16                haas berkeley edu               0.312            48           48
    7                                                  []              2          19              shall lessee lessor               0.663            31           31
    8                                                  []              2          21                  kean normal oct               0.544            25           25
    9                                                  []              2          23            dasovich teneo normal               0.223           198          198
    10                                                 []              2          31           dupre black catalytica               0.458            16           16
    11                                                 []              2          33        ect enron_development hou               0.334            93           93
    12                                                 []              2          36          party transaction shall               0.526            45           45
    13                                                 []              2          38        transmission power market               0.214            93           93
    14                                                 []              2          43         agreement subject normal               0.101           577          577
    15                                                 []              2          64           nemec registration ect               0.340            26           26
    16                                                 []              2          67          sanders haedicke normal               0.252           130          130
    17                                                 []              2          74          court million plaintiff               0.568             8            8
    18                                                 []              2          76            mtg migration outlook               0.524            24           24
    19                                                 []              2          78   test administrative recipients               0.283           116          116
    20                                                 []              2          83                tenet normal test               0.120           618          618
    21                                                 []              2         104                 thu tenet normal               0.346            65           65
    22                                                 []              2         107                    nov wed tenet               0.507            18           18
    23                                                 []              2         109                wed tenet houston               0.493            21           21

    4.a. Optimal sampling (LSI + Birch clustering)
     GET http://localhost:5001/api/v0/clustering/birch/23322e00eee34406
        .. computed in 0.1s
        cluster_id  cluster_similarity  cluster_size                                          documents
    0           34               0.425            63  [{'document_id': 2030625, 'similarity': 0.8369...
    1            3               0.950            59  [{'document_id': 5041, 'similarity': 0.9994696...
    2           29               0.515            55  [{'document_id': 314721, 'similarity': 0.64718...
    3           44               0.348            55  [{'document_id': 2024929, 'similarity': 0.5760...
    4           49               0.444            55  [{'document_id': 609961, 'similarity': 0.87480...
    5           55               0.260            50  [{'document_id': 1915456, 'similarity': 0.4099...
    6           81               0.476            50  [{'document_id': 154449, 'similarity': 0.85039...
    7           88               0.375            50  [{'document_id': 1768900, 'similarity': 0.7023...
    8           45               0.330            49  [{'document_id': 85849, 'similarity': 0.591680...
    9           84               0.390            47  [{'document_id': 4624, 'similarity': 0.5859821...
    10           8               0.378            45  [{'document_id': 1306449, 'similarity': 0.5860...
    11          37               0.526            45  [{'document_id': 165649, 'similarity': 0.89723...
    12          96               0.370            45  [{'document_id': 2676496, 'similarity': 0.5694...
    13          97               0.298            45  [{'document_id': 239121, 'similarity': 0.44257...
    14         106               0.403            45  [{'document_id': 2325625, 'similarity': 0.6206...
    15          90               0.331            42  [{'document_id': 1232100, 'similarity': 0.5741...
    16         100               0.383            42  [{'document_id': 3171961, 'similarity': 0.7157...
    17          10               0.335            41  [{'document_id': 108241, 'similarity': 0.48101...
    18          13               0.436            40  [{'document_id': 28900, 'similarity': 0.547416...
    19          72               0.445            40  [{'document_id': 1387684, 'similarity': 0.6078...
    20         101               0.407            40  [{'document_id': 313600, 'similarity': 0.66657...
    21          28               0.335            39  [{'document_id': 5076009, 'similarity': 0.5785...
    22          11               0.363            38  [{'document_id': 276676, 'similarity': 0.52022...
    23          52               0.377            38  [{'document_id': 1100401, 'similarity': 0.7137...
    24          59               0.293            38  [{'document_id': 5808100, 'similarity': 0.5095...
    25         103               0.407            38  [{'document_id': 2396304, 'similarity': 0.6039...
    26          18               0.361            35  [{'document_id': 514089, 'similarity': 0.64278...
    27          56               0.342            35  [{'document_id': 2524921, 'similarity': 0.5551...
    28          42               0.379            34  [{'document_id': 144400, 'similarity': 0.68667...
    29          89               0.383            32  [{'document_id': 1404225, 'similarity': 0.5276...
    ..         ...                 ...           ...                                                ...
    38          80               0.435            27  [{'document_id': 21025, 'similarity': 0.630877...
    39          92               0.407            27  [{'document_id': 1887876, 'similarity': 0.6596...
    40          85               0.386            26  [{'document_id': 524176, 'similarity': 0.59707...
    41           7               0.423            25  [{'document_id': 48841, 'similarity': 0.659089...
    42          22               0.544            25  [{'document_id': 5564881, 'similarity': 0.7735...
    43          71               0.377            25  [{'document_id': 2920681, 'similarity': 0.5278...
    44         102               0.384            25  [{'document_id': 5846724, 'similarity': 0.5990...
    45          47               0.405            24  [{'document_id': 125316, 'similarity': 0.61346...
    46          53               0.396            24  [{'document_id': 1628176, 'similarity': 0.7415...
    47          61               0.337            24  [{'document_id': 763876, 'similarity': 0.49455...
    48          77               0.524            24  [{'document_id': 5621641, 'similarity': 0.6364...
    49          95               0.355            24  [{'document_id': 2111209, 'similarity': 0.5724...
    50          46               0.414            23  [{'document_id': 3790809, 'similarity': 0.6067...
    51          68               0.408            23  [{'document_id': 2913849, 'similarity': 0.6604...
    52          79               0.359            23  [{'document_id': 866761, 'similarity': 0.57871...
    53           6               0.642            22  [{'document_id': 4165681, 'similarity': 0.8957...
    54          48               0.394            22  [{'document_id': 369664, 'similarity': 0.67363...
    55           9               0.416            21  [{'document_id': 1764, 'similarity': 0.7072555...
    56          40               0.400            21  [{'document_id': 921600, 'similarity': 0.58430...
    57          99               0.389            21  [{'document_id': 217156, 'similarity': 0.59465...
    58         110               0.493            21  [{'document_id': 1742400, 'similarity': 0.6860...
    59          69               0.416            20  [{'document_id': 2992900, 'similarity': 0.5397...
    60         105               0.504            20  [{'document_id': 3587236, 'similarity': 0.7406...
    61          66               0.408            19  [{'document_id': 1085764, 'similarity': 0.5933...
    62          24               0.364            18  [{'document_id': 408321, 'similarity': 0.46681...
    63          91               0.397            18  [{'document_id': 1968409, 'similarity': 0.5921...
    64         108               0.507            18  [{'document_id': 2893401, 'similarity': 0.6502...
    65          30               0.526            17  [{'document_id': 290521, 'similarity': 0.66970...
    66          73               0.565            17  [{'document_id': 3802500, 'similarity': 0.7575...
    67          94               0.448            17  [{'document_id': 3020644, 'similarity': 0.6674...

    [68 rows x 4 columns]

    5. Delete the extracted features
     DELETE http://localhost:5001/api/v0/feature-extraction/ef60bf5a05214071




|


.. code-block:: python


    import os.path
    import pandas as pd
    from time import time
    import requests

    pd.options.display.float_format = '{:,.3f}'.format


    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    print(" 0. Load the example dataset")
    url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
    print(" GET", url)
    input_ds = requests.get(url).json()

    # To use a custom dataset, simply specify the following variables
    data_dir = input_ds['metadata']['data_dir']
    dataset_definition = [{'document_id': row['document_id'],
                           'file_path': os.path.join(data_dir, row['file_path'])}
                          for row in input_ds['dataset']]

    # # 1. Feature extraction (non hashed)

    print("\n1.a Load dataset and initalize feature extraction")
    url = BASE_URL + '/feature-extraction'
    print(" POST", url)
    fe_opts = {  # 'min_df': 4, 'max_df': 0.75  # filter out (too)/(un)frequent words
               }
    res = requests.post(url, json=fe_opts).json()

    dsid = res['id']
    print("   => received {}".format(list(res.keys())))
    print("   => dsid = {}".format(dsid))


    print("\n1.b Run feature extraction")
    # progress status is available for the hashed version only
    url = BASE_URL+'/feature-extraction/{}'.format(dsid)
    print(" POST", url)
    res = requests.post(url, json={'dataset_definition': dataset_definition})

    print("\n1.d. check the parameters of the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(' GET', url)
    res = requests.get(url).json()

    print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items()
                     if "filenames" not in key]))

    print("\n2. Calculate LSI")

    url = BASE_URL + '/lsi/'
    print("POST", url)

    n_components = 300
    res = requests.post(url,
                        json={'n_components': n_components,
                              'parent_id': dsid
                              }).json()

    lsi_id = res['id']
    print('  => LSI model id = {}'.format(lsi_id))
    print(('  => SVD decomposition with {} dimensions '
           'explaining {:.2f} % variabilty of the data')
          .format(n_components, res['explained_variance']*100))

    # # 3. Document Clustering (LSI + K-Means)

    print("\n3.a. Document clustering (LSI + K-means)")

    url = BASE_URL + '/clustering/k-mean/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': 10,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n3.b. Computing cluster labels")
    url = BASE_URL + '/clustering/k-mean/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()


    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    print(pd.DataFrame(data))


    # # 4. Document Clustering (LSI + Birch Clustering)

    print("\n4.a. Document clustering (LSI + Birch clustering)")

    url = BASE_URL + '/clustering/birch/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': -1,
                              'min_similarity': 0.7,
                              'branching_factor': 20,
                              'max_tree_depth': 2,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n4.b. Computing cluster labels")
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print(pd.DataFrame(data))

    # # 4. Optimal sampling (LSI + Birch Clustering)

    print("\n4.a. Optimal sampling (LSI + Birch clustering)")

    t0 = time()
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'return_optimal_sampling': True,
                             'sampling_min_coverage': 0.9
                             }).json()
    t1 = time()
    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']

    print(pd.DataFrame(data))

    # 4. Cleaning
    print("\n5. Delete the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(" DELETE", url)
    requests.delete(url)

**Total running time of the script:** ( 0 minutes  11.138 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_clustering.py <REST_clustering.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_clustering.ipynb <REST_clustering.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
