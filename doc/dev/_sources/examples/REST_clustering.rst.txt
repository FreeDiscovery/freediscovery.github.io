

.. _sphx_glr_examples_REST_clustering.py:


Clustering Example [REST API]
-----------------------------

Cluster documents into clusters





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['id']
       => dsid = 493db19a97fb42be

    1.b Run feature extraction
     POST http://localhost:5001/api/v0/feature-extraction/493db19a97fb42be

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/493db19a97fb42be
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: /home/ubuntu/freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - parse_email_headers: False
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: False
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = e7a71cff498649ef
      => SVD decomposition with 300 dimensions explaining 90.01 % variabilty of the data

    3.a. Document clustering (LSI + K-means)
     POST http://localhost:5001/api/v0/clustering/k-mean/
         => model id = 583c157fb8b0400e

    3.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/k-mean/583c157fb8b0400e
        .. computed in 1.3s
       cluster_id                     cluster_label  cluster_similarity  cluster_size  n_documents
    0           0    test administrative recipients               0.219           213          213
    1           1                  ect hou november               0.320           121          121
    2           2             mon outlook migration               0.188           235          235
    3           3                  tenet oct normal               0.197           237          237
    4           4            rewrite address server               1.000            56           56
    5           5              tue tenet conference               0.232           186          186
    6           6                fri sanders normal               0.252           157          157
    7           7                    wed normal nov               0.278           163          163
    8           8  enron_development services shall               0.359            98           98
    9           9                    tana jones new               0.080           999          999

    4.a. Document clustering (LSI + Birch clustering)
     POST http://localhost:5001/api/v0/clustering/birch/
         => model id = 96e2e184bb6647e2

    4.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/birch/96e2e184bb6647e2
        .. computed in 2.3s
                                                 children  cluster_depth  cluster_id                          cluster_label  cluster_similarity  cluster_size  n_documents
    0   [1, 4, 9, 12, 22, 27, 45, 49, 58, 65, 68, 70, 76]              0           0                        normal test ect               0.071          2465         2465
    1                                              [2, 3]              1           1                 rewrite address server               0.497           119          119
    2                                                  []              2           2                 rewrite address server               0.701            81           81
    3                                                  []              2           3                   shackleton load test               0.406            38           38
    4                                        [5, 6, 7, 8]              1           4         administrative recipients test               0.272           128          128
    5                                                  []              2           5         test administrative recipients               0.419            51           51
    6                                                  []              2           6              jones tana administrative               0.317            30           30
    7                                                  []              2           7                       jones tana meter               0.357            26           26
    8                                                  []              2           8       shults administrative recipients               0.429            21           21
    9                                            [10, 11]              1           9                         ect hou advice               0.366            89           89
    10                                                 []              2          10                   advice mexico update               0.467            23           23
    11                                                 []              2          11                          ect hou taffy               0.453            66           66
    12               [13, 14, 15, 16, 17, 18, 19, 20, 21]              1          12          enron_development load normal               0.192           251          251
    13                                                 []              2          13      enron_development tiger committee               0.348            51           51
    14                                                 []              2          14     company confirmation determination               0.459            26           26
    15                                                 []              2          15               kean market transmission               0.395            38           38
    16                                                 []              2          16          gdr enron_development hagerty               0.388            33           33
    17                                                 []              2          17                   services hyvl energy               0.340            21           21
    18                                                 []              2          18                  website online condor               0.563             6            6
    19                                                 []              2          19                      fuel enron notice               1.000             1            1
    20                                                 []              2          20                       teneo normal oct               0.504            54           54
    21                                                 []              2          21                        load meet teneo               0.507            21           21
    22                                   [23, 24, 25, 26]              1          22                  shall party agreement               0.229           212          212
    23                                                 []              2          23                   brazil trade account               0.352            22           22
    24                                                 []              2          24                party transaction shall               0.361            84           84
    25                                                 []              2          25                    shall lessee lessor               0.425            50           50
    26                                                 []              2          26               shall customer agreement               0.436            56           56
    27  [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 3...              1          27                   sanders nemec normal               0.128           419          419
    28                                                 []              2          28                       dead horse awais               0.380            30           30
    29                                                 []              2          29                      way nemec systems               0.425            15           15
    ..                                                ...            ...         ...                                    ...                 ...           ...          ...
    66                                                 []              2          66                 haedicke update canada               0.340            32           32
    67                                                 []              2          67          sager sager_elizabeth nicolay               0.441            19           19
    68                                               [69]              1          68                  information ect court               0.489            13           13
    69                                                 []              2          69                  information ect court               0.489            13           13
    70                               [71, 72, 73, 74, 75]              1          70      shackleton_sara teneo enrononline               0.170           156          156
    71                                                 []              2          71                  power language thanks               0.443            17           17
    72                                                 []              2          72                      berkeley haas edu               0.349            24           24
    73                                                 []              2          73       enrononline americancentury usvi               0.328            42           42
    74                                                 []              2          74            shackleton_sara teneo group               0.343            25           25
    75                                                 []              2          75                       flynn class smud               0.302            48           48
    76  [77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 8...              1          76              mtg enron shackleton_sara               0.104           576          576
    77                                                 []              2          77          issues enron_development cone               0.300            69           69
    78                                                 []              2          78     november regards enron_development               0.353            40           40
    79                                                 []              2          79                    isda freyre rodolfo               0.360            39           39
    80                                                 []              2          80                        lay masters day               0.420            15           15
    81                                                 []              2          81                     calo people master               0.405            30           30
    82                                                 []              2          82             internet enron derivatives               0.357            23           23
    83                                                 []              2          83                      stay motion gibbs               0.317            21           21
    84                                                 []              2          84                     week southern duke               0.362            25           25
    85                                                 []              2          85                       enron jones tana               0.356            26           26
    86                                                 []              2          86                      enron online tana               0.374            26           26
    87                                                 []              2          87                  power haedicke eb3325               0.535             8            8
    88                                                 []              2          88                 project party training               0.382            25           25
    89                                                 []              2          89  kincannon elbertson elbertson_janette               0.348            37           37
    90                                                 []              2          90                murray ellis mccullough               0.302            27           27
    91                                                 []              2          91     shackleton_sara message shackleton               0.379            40           40
    92                                                 []              2          92            energy services midamerican               0.347            26           26
    93                                                 []              2          93                     enron nicolay corp               0.341            17           17
    94                                                 []              2          94                     mtg team migration               0.413            39           39
    95                                                 []              2          95                        mtg budget room               0.365            43           43

    [96 rows x 7 columns]

    4.a. Optimal sampling (LSI + Birch clustering)
     GET http://localhost:5001/api/v0/clustering/birch/96e2e184bb6647e2
        .. computed in 0.1s
        cluster_id  cluster_similarity  cluster_size                                          documents
    0           24               0.361            84  [{'document_id': 165649, 'similarity': 0.80372...
    1            2               0.701            81  [{'document_id': 5041, 'similarity': 0.9863676...
    2           77               0.300            69  [{'document_id': 131769, 'similarity': 0.69004...
    3           11               0.453            66  [{'document_id': 2030625, 'similarity': 0.8182...
    4           26               0.436            56  [{'document_id': 609961, 'similarity': 0.87300...
    5           52               0.376            55  [{'document_id': 2334784, 'similarity': 0.6313...
    6           20               0.504            54  [{'document_id': 358801, 'similarity': 0.67022...
    7            5               0.419            51  [{'document_id': 154449, 'similarity': 0.80668...
    8           13               0.348            51  [{'document_id': 37636, 'similarity': 0.623985...
    9           25               0.425            50  [{'document_id': 1567504, 'similarity': 0.8164...
    10          53               0.383            48  [{'document_id': 3097600, 'similarity': 0.5951...
    11          75               0.302            48  [{'document_id': 10201, 'similarity': 0.472924...
    12          42               0.340            47  [{'document_id': 1585081, 'similarity': 0.5784...
    13          95               0.365            43  [{'document_id': 5480281, 'similarity': 0.6498...
    14          73               0.328            42  [{'document_id': 1229881, 'similarity': 0.6142...
    15          78               0.353            40  [{'document_id': 5076009, 'similarity': 0.6272...
    16          91               0.379            40  [{'document_id': 4601025, 'similarity': 0.5327...
    17          79               0.360            39  [{'document_id': 4765489, 'similarity': 0.6077...
    18          94               0.413            39  [{'document_id': 5555449, 'similarity': 0.5921...
    19           3               0.406            38  [{'document_id': 65536, 'similarity': 0.605545...
    20          15               0.395            38  [{'document_id': 145924, 'similarity': 0.59397...
    21          89               0.348            37  [{'document_id': 2647129, 'similarity': 0.6800...
    22          33               0.398            35  [{'document_id': 1664100, 'similarity': 0.6199...
    23          16               0.388            33  [{'document_id': 91809, 'similarity': 0.784593...
    24          34               0.321            33  [{'document_id': 202500, 'similarity': 0.53145...
    25          41               0.454            33  [{'document_id': 1313316, 'similarity': 0.6488...
    26          46               0.438            33  [{'document_id': 4624, 'similarity': 0.7310847...
    27          47               0.389            33  [{'document_id': 514089, 'similarity': 0.67660...
    28          50               0.349            32  [{'document_id': 1855044, 'similarity': 0.5856...
    29          54               0.420            32  [{'document_id': 1874161, 'similarity': 0.6629...
    ..         ...                 ...           ...                                                ...
    33           6               0.317            30  [{'document_id': 215296, 'similarity': 0.49832...
    34          28               0.380            30  [{'document_id': 206116, 'similarity': 0.62685...
    35          37               0.470            30  [{'document_id': 3980025, 'similarity': 0.6672...
    36          44               0.507            30  [{'document_id': 5846724, 'similarity': 0.6932...
    37          59               0.297            30  [{'document_id': 2673225, 'similarity': 0.5548...
    38          81               0.405            30  [{'document_id': 3779136, 'similarity': 0.6946...
    39          30               0.392            29  [{'document_id': 362404, 'similarity': 0.75803...
    40          90               0.302            27  [{'document_id': 2873025, 'similarity': 0.5071...
    41           7               0.357            26  [{'document_id': 341056, 'similarity': 0.57437...
    42          14               0.459            26  [{'document_id': 53361, 'similarity': 0.826623...
    43          48               0.420            26  [{'document_id': 3326976, 'similarity': 0.8051...
    44          85               0.356            26  [{'document_id': 2076481, 'similarity': 0.5978...
    45          86               0.374            26  [{'document_id': 1962801, 'similarity': 0.6206...
    46          92               0.347            26  [{'document_id': 1435204, 'similarity': 0.5933...
    47          74               0.343            25  [{'document_id': 4622500, 'similarity': 0.4617...
    48          84               0.362            25  [{'document_id': 3996001, 'similarity': 0.5493...
    49          88               0.382            25  [{'document_id': 781456, 'similarity': 0.58615...
    50          32               0.416            24  [{'document_id': 697225, 'similarity': 0.72412...
    51          72               0.349            24  [{'document_id': 463761, 'similarity': 0.50191...
    52          10               0.467            23  [{'document_id': 25921, 'similarity': 0.803097...
    53          40               0.320            23  [{'document_id': 1648656, 'similarity': 0.4939...
    54          62               0.569            23  [{'document_id': 2903616, 'similarity': 0.6784...
    55          82               0.357            23  [{'document_id': 1069156, 'similarity': 0.5793...
    56          23               0.352            22  [{'document_id': 24964, 'similarity': 0.480388...
    57          56               0.425            22  [{'document_id': 3171961, 'similarity': 0.7337...
    58          57               0.514            22  [{'document_id': 1893376, 'similarity': 0.7783...
    59          60               0.361            22  [{'document_id': 1512900, 'similarity': 0.5577...
    60           8               0.429            21  [{'document_id': 255025, 'similarity': 0.66331...
    61          17               0.340            21  [{'document_id': 294849, 'similarity': 0.48808...
    62          21               0.507            21  [{'document_id': 290521, 'similarity': 0.66962...

    [63 rows x 4 columns]

    5. Delete the extracted features
     DELETE http://localhost:5001/api/v0/feature-extraction/493db19a97fb42be




|


.. code-block:: python


    import os.path
    import pandas as pd
    from time import time
    import requests

    pd.options.display.float_format = '{:,.3f}'.format


    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    print(" 0. Load the example dataset")
    url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
    print(" GET", url)
    input_ds = requests.get(url).json()

    # To use a custom dataset, simply specify the following variables
    data_dir = input_ds['metadata']['data_dir']
    dataset_definition = [{'document_id': row['document_id'],
                           'file_path': os.path.join(data_dir, row['file_path'])}
                          for row in input_ds['dataset']]

    # # 1. Feature extraction (non hashed)

    print("\n1.a Load dataset and initalize feature extraction")
    url = BASE_URL + '/feature-extraction'
    print(" POST", url)
    fe_opts = {  # 'min_df': 4, 'max_df': 0.75  # filter out (too)/(un)frequent words
               }
    res = requests.post(url, json=fe_opts).json()

    dsid = res['id']
    print("   => received {}".format(list(res.keys())))
    print("   => dsid = {}".format(dsid))


    print("\n1.b Run feature extraction")
    # progress status is available for the hashed version only
    url = BASE_URL+'/feature-extraction/{}'.format(dsid)
    print(" POST", url)
    res = requests.post(url, json={'dataset_definition': dataset_definition})

    print("\n1.d. check the parameters of the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(' GET', url)
    res = requests.get(url).json()

    print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items()
                     if "filenames" not in key]))

    print("\n2. Calculate LSI")

    url = BASE_URL + '/lsi/'
    print("POST", url)

    n_components = 300
    res = requests.post(url,
                        json={'n_components': n_components,
                              'parent_id': dsid
                              }).json()

    lsi_id = res['id']
    print('  => LSI model id = {}'.format(lsi_id))
    print(('  => SVD decomposition with {} dimensions '
           'explaining {:.2f} % variabilty of the data')
          .format(n_components, res['explained_variance']*100))

    # # 3. Document Clustering (LSI + K-Means)

    print("\n3.a. Document clustering (LSI + K-means)")

    url = BASE_URL + '/clustering/k-mean/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': 10,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n3.b. Computing cluster labels")
    url = BASE_URL + '/clustering/k-mean/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()


    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    print(pd.DataFrame(data))


    # # 4. Document Clustering (LSI + Birch Clustering)

    print("\n4.a. Document clustering (LSI + Birch clustering)")

    url = BASE_URL + '/clustering/birch/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': -1,
                              'min_similarity': 0.7,
                              'branching_factor': 20,
                              'max_tree_depth': 2,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n4.b. Computing cluster labels")
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print(pd.DataFrame(data))

    # # 4. Optimal sampling (LSI + Birch Clustering)

    print("\n4.a. Optimal sampling (LSI + Birch clustering)")

    t0 = time()
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'return_optimal_sampling': True,
                             'sampling_min_coverage': 0.9
                             }).json()
    t1 = time()
    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']

    print(pd.DataFrame(data))

    # 4. Cleaning
    print("\n5. Delete the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(" DELETE", url)
    requests.delete(url)

**Total running time of the script:** ( 0 minutes  17.886 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_clustering.py <REST_clustering.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_clustering.ipynb <REST_clustering.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
