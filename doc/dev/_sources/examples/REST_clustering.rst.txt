

.. _sphx_glr_examples_REST_clustering.py:


Clustering Example [REST API]
-----------------------------

Cluster documents into clusters





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['filenames', 'id']
       => dsid = 3bdc9144ed7649f2

    1.b Run feature extraction
     POST http://localhost:5001/api/v0/feature-extraction/3bdc9144ed7649f2

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/3bdc9144ed7649f2
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: /home/ubuntu/freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 0.75
         - min_df: 4.0
         - n_features: 30001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - parse_email_headers: False
         - stop_words: None
         - sublinear_tf: True
         - use_hashing: False
         - use_idf: True

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = bd356f2631654a66
      => SVD decomposition with 100 dimensions explaining 53.28 % variabilty of the data

    3.a. Document clustering (LSI + K-means)
     POST http://localhost:5001/api/v0/clustering/k-mean/
         => model id = a89e52c9a1244d77

    3.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/k-mean/a89e52c9a1244d77
        .. computed in 1.0s
       cluster_id                  cluster_label  cluster_similarity  cluster_size  n_documents
    0           0         rewrite server address               1.000            56           56
    1           1    transaction tana shackleton               0.175           529          529
    2           2          energy enron services               0.369           221          221
    3           3         migration outlook team               0.437           125          125
    4           4                 ect eb3325 hou               0.365           148          148
    5           5          dasovich tue haedicke               0.230           361          361
    6           6  teneo enron_development enron               0.213           439          439
    7           7                  tenet mon nov               0.298           257          257
    8           8              clair ect trading               0.329           170          170
    9           9                sanders thu nov               0.375           159          159

    4.a. Document clustering (LSI + Birch clustering)
     POST http://localhost:5001/api/v0/clustering/birch/
         => model id = 61008020a2cf4ef1

    4.b. Computing cluster labels
     GET http://localhost:5001/api/v0/clustering/birch/61008020a2cf4ef1
        .. computed in 2.1s
                                                 children  cluster_depth  cluster_id                     cluster_label  cluster_similarity  cluster_size  n_documents
    0                                             [1, 20]              0           0                      test ect oct               0.109          2465         2465
    1   [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...              1           1                    ect tenet test               0.130          1538         1538
    2                                                  []              2           2        mon enron_development cone               0.366            91           91
    3                                                  []              2           3            rewrite server address               0.559           109          109
    4                                                  []              2           4                  shall party kean               0.396           155          155
    5                                                  []              2           5                     usvi gdr pier               0.428            51           51
    6                                                  []              2           6              marcelo tozzini afac               0.511            59           59
    7                                                  []              2           7                tiger guaranty ena               0.482            48           48
    8                                                  []              2           8              deseret calo ruppert               0.390            81           81
    9                                                  []              2           9                  tana jones enron               0.394           135          135
    10                                                 []              2          10                      wed oct load               0.358           106          106
    11                                                 []              2          11                 berkeley haas edu               0.403           107          107
    12                                                 []              2          12         ect enron_development hou               0.474            54           54
    13                                                 []              2          13           sanders conference dead               0.490            80           80
    14                                                 []              2          14                       lon ect tue               0.370            97           97
    15                                                 []              2          15   fri ricafrente ricafrente_david               0.382           114          114
    16                                                 []              2          16                 meeting tenet ogc               0.447            61           61
    17                                                 []              2          17                     thu tenet oct               0.461            68           68
    18                                                 []              2          18                  hendry duke week               0.434            45           45
    19                                                 []              2          19                     tue nov tenet               0.361            77           77
    20  [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 3...              1          20             test recipients teneo               0.153           927          927
    21                                                 []              2          21               cini isda argentina               0.469            45           45
    22                                                 []              2          22           teneo taylor_mark enron               0.398            63           63
    23                                                 []              2          23           haedicke shackleton nov               0.425            91           91
    24                                                 []              2          24                townsend nemec net               0.556            23           23
    25                                                 []              2          25          dasovich test recipients               0.357           146          146
    26                                                 []              2          26                   nemec doc enron               0.416            96           96
    27                                                 []              2          27            energy services market               0.473            78           78
    28                                                 []              2          28         kincannon lunch migration               0.286            84           84
    29                                                 []              2          29     catalytica confirmation dupre               0.410            69           69
    30                                                 []              2          30            seminar mexico midland               0.618            12           12
    31                                                 []              2          31              clair attorney enron               0.343            82           82
    32                                                 []              2          32                  flynn smud teneo               0.363            67           67
    33                                                 []              2          33          forster canadian masters               0.505            23           23
    34                                                 []              2          34  shackleton teneo shackleton_sara               0.432            48           48

    4.a. Optimal sampling (LSI + Birch clustering)
     GET http://localhost:5001/api/v0/clustering/birch/61008020a2cf4ef1
        .. computed in 0.4s
        cluster_id  cluster_similarity  cluster_size                                          documents
    0            0               0.396           155  [{'document_id': 299209, 'similarity': 0.39617...
    1            1               0.357           146  [{'document_id': 534361, 'similarity': 0.35661...
    2            2               0.394           135  [{'document_id': 215296, 'similarity': 0.39418...
    3            3               0.382           114  [{'document_id': 2471184, 'similarity': 0.3818...
    4            4               0.559           109  [{'document_id': 5041, 'similarity': 0.5587970...
    5            5               0.403           107  [{'document_id': 439569, 'similarity': 0.40273...
    6            6               0.358           106  [{'document_id': 414736, 'similarity': 0.35759...
    7            7               0.370            97  [{'document_id': 3164841, 'similarity': 0.3697...
    8            8               0.416            96  [{'document_id': 753424, 'similarity': 0.41640...
    9            9               0.366            91  [{'document_id': 625, 'similarity': 0.36597789...
    10          10               0.425            91  [{'document_id': 1002001, 'similarity': 0.4246...
    11          11               0.286            84  [{'document_id': 2647129, 'similarity': 0.2863...
    12          12               0.343            82  [{'document_id': 1382976, 'similarity': 0.3432...
    13          13               0.390            81  [{'document_id': 703921, 'similarity': 0.38955...
    14          14               0.490            80  [{'document_id': 3814209, 'similarity': 0.4900...
    15          15               0.473            78  [{'document_id': 207025, 'similarity': 0.47280...
    16          16               0.361            77  [{'document_id': 1827904, 'similarity': 0.3609...
    17          17               0.410            69  [{'document_id': 4955076, 'similarity': 0.4100...
    18          18               0.461            68  [{'document_id': 1752976, 'similarity': 0.4614...
    19          19               0.363            67  [{'document_id': 5221225, 'similarity': 0.3630...
    20          20               0.398            63  [{'document_id': 3352561, 'similarity': 0.3977...
    21          21               0.447            61  [{'document_id': 3052009, 'similarity': 0.4470...
    22          22               0.511            59  [{'document_id': 99856, 'similarity': 0.510564...
    23          23               0.474            54  [{'document_id': 3334276, 'similarity': 0.4737...
    24          24               0.428            51  [{'document_id': 1234321, 'similarity': 0.4278...

    5. Delete the extracted features
     DELETE http://localhost:5001/api/v0/feature-extraction/3bdc9144ed7649f2




|


.. code-block:: python


    import os.path
    import pandas as pd
    from time import time
    import requests

    pd.options.display.float_format = '{:,.3f}'.format


    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    print(" 0. Load the example dataset")
    url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
    print(" GET", url)
    input_ds = requests.get(url).json()

    # To use a custom dataset, simply specify the following variables
    data_dir = input_ds['metadata']['data_dir']
    dataset_definition = [{'document_id': row['document_id'],
                           'file_path': os.path.join(data_dir, row['file_path'])}
                          for row in input_ds['dataset']]

    # # 1. Feature extraction (non hashed)

    print("\n1.a Load dataset and initalize feature extraction")
    url = BASE_URL + '/feature-extraction'
    print(" POST", url)
    fe_opts = {'dataset_definition': dataset_definition,
               'use_idf': 1, 'n_features': 30001,
               'min_df': 4, 'max_df': 0.75  # filter out (too)/(un)frequent words
               }
    res = requests.post(url, json=fe_opts).json()

    dsid = res['id']
    print("   => received {}".format(list(res.keys())))
    print("   => dsid = {}".format(dsid))


    print("\n1.b Run feature extraction")
    # progress status is available for the hashed version only
    url = BASE_URL+'/feature-extraction/{}'.format(dsid)
    print(" POST", url)
    res = requests.post(url)

    print("\n1.d. check the parameters of the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(' GET', url)
    res = requests.get(url).json()

    print('\n'.join(['     - {}: {}'.format(key, val) for key, val in res.items()
                     if "filenames" not in key]))

    print("\n2. Calculate LSI")

    url = BASE_URL + '/lsi/'
    print("POST", url)

    n_components = 100
    res = requests.post(url,
                        json={'n_components': n_components,
                              'parent_id': dsid
                              }).json()

    lsi_id = res['id']
    print('  => LSI model id = {}'.format(lsi_id))
    print(('  => SVD decomposition with {} dimensions '
           'explaining {:.2f} % variabilty of the data')
          .format(n_components, res['explained_variance']*100))

    # # 3. Document Clustering (LSI + K-Means)

    print("\n3.a. Document clustering (LSI + K-means)")

    url = BASE_URL + '/clustering/k-mean/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': 10,
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n3.b. Computing cluster labels")
    url = BASE_URL + '/clustering/k-mean/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()


    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    print(pd.DataFrame(data))


    # # 4. Document Clustering (LSI + Birch Clustering)

    print("\n4.a. Document clustering (LSI + Birch clustering)")

    url = BASE_URL + '/clustering/birch/'
    print(" POST", url)
    t0 = time()
    res = requests.post(url,
                        json={'parent_id': lsi_id,
                              'n_clusters': -1,
                              'min_similarity': 0.7,
                              'branching_factor': 20
                              }).json()

    mid = res['id']
    print("     => model id = {}".format(mid))

    print("\n4.b. Computing cluster labels")
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'n_top_words': 3
                             }).json()
    t1 = time()

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']
    for row in data:
        row['n_documents'] = len(row.pop('documents'))

    print(pd.DataFrame(data))

    # # 4. Optimal sampling (LSI + Birch Clustering)

    print("\n4.a. Optimal sampling (LSI + Birch clustering)")

    t0 = time()
    url = BASE_URL + '/clustering/birch/{}'.format(mid)
    print(" GET", url)
    res = requests.get(url,
                       json={'return_optimal_sampling': True,
                             'sampling_min_coverage': 0.9
                             }).json()
    t1 = time()
    print('    .. computed in {:.1f}s'.format(t1 - t0))
    data = res['data']

    print(pd.DataFrame(data))

    # 4. Cleaning
    print("\n5. Delete the extracted features")
    url = BASE_URL + '/feature-extraction/{}'.format(dsid)
    print(" DELETE", url)
    requests.delete(url)

**Total running time of the script:** ( 0 minutes  8.320 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_clustering.py <REST_clustering.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_clustering.ipynb <REST_clustering.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
