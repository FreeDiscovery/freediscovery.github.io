

.. _sphx_glr_examples_clustering_example_python.py:


Document Clustering example (Python)
------------------------------------

An example of clustering using Python API





.. rst-class:: sphx-glr-script-out

 Out::

    .. computed in 3.9s
       N_documents                                      cluster_names
    2          583  [ect, enron_development, recipients, administr...
    1          561  [recipients, group, administrative, test, tene...
    4          330  [ect, enron_development, hou, supply, group, t...
    3          260  [ect, group, recipients, administrative, enron...
    8          199  [energy, enron, enrononline, shall, trading, m...
    7          179  [enron, ect, enrononline, trading, enron_devel...
    5          138  [shall, party, transaction, agreement, price, ...
    0          102  [ect, enrononline, enron_development, group, h...
    6           63    [rewrite, server, address, smtp, mail, virtual]
    9           50           [berkeley, edu, haas, alias, ect, group]
        .. computed in 3.9s
       N_documents                                      cluster_names
    6          615  [recipients, administrative, group, test, ect,...
    0          562  [ect, enron_development, recipients, hou, admi...
    1          368  [ect, enron_development, recipients, administr...
    3          301  [ect, enron_development, hou, ena, products, e...
    2          200  [enron, energy, enrononline, company, ect, mar...
    5          156  [enron, ect, corp, enron_development, hou, north]
    7           87  [shall, agreement, party, customer, lessee, op...
    4           82  [shall, party, transaction, price, floating, d...
    9           63    [rewrite, server, address, smtp, mail, virtual]
    8           31     [berkeley, edu, haas, alias, enrononline, ect]




|


.. code-block:: python


    import pandas as pd
    from IPython.display import display
    from freediscovery.text import FeatureVectorizer
    from freediscovery.cluster import Clustering
    from freediscovery.utils import _silent
    from time import time

    pd.options.display.float_format = '{:,.3f}'.format

    dataset_name = "treclegal09_2k_subset"

    data_dir = "../freediscovery_shared/{}".format(dataset_name)
    examples_to_server_path = "../" # relative path between this file and the FreeDiscovery source folder

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL


    # # 1. Feature extraction (non hashed)

    n_features = 30000
    cache_dir = '/tmp/'

    fe = FeatureVectorizer(cache_dir=cache_dir)
    uuid = fe.preprocess("../"+data_dir+'/data',
                         n_features=n_features, use_hashing=False,
                         use_idf=True, stop_words='english')
    uuid, filenames = fe.transform()


    # # 2. Document Clustering (LSI + K-Means)

    cat = Clustering(cache_dir=cache_dir, dsid=uuid)

    n_clusters = 10
    n_top_words = 6
    lsi_components = 50


    def repr_clustering(_labels, _terms):
        out = []
        for ridx, row in enumerate(_terms):
            out.append({'cluster_names': row, 'N_documents': (_labels == ridx).sum()})
        out = pd.DataFrame(out).sort_values('N_documents', ascending=False)
        return out


    t0 = time()
    with _silent('stderr'): # ignore some deprecation warnings
        labels, tree  = cat.k_means(n_clusters, lsi_components=lsi_components)
        terms = cat.compute_labels(n_top_words=n_top_words)
    t1 = time()

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    display(repr_clustering(labels, terms))


    # # 3. Document Clustering (LSI + Ward Hierarchical Clustering)

    t0 = time()
    with _silent('stderr'): # ignore some deprecation warnings
        labels, tree = cat.ward_hc(n_clusters,
                                   lsi_components=lsi_components,
                                   n_neighbors=5   # this is the connectivity constraint
                                   )
        terms = cat.compute_labels(n_top_words=n_top_words)
    t1 = time()

    print('    .. computed in {:.1f}s'.format(t1 - t0))
    display(repr_clustering(labels, terms))

**Total running time of the script:** ( 0 minutes  10.700 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: clustering_example_python.py <clustering_example_python.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: clustering_example_python.ipynb <clustering_example_python.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
