{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nHierarchical Clustering Example\n===============================\n\nVisualize hierarchical clusters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path\nimport pandas as pd\nfrom time import time\nimport requests\nfrom graphviz import Digraph\n\n\ndataset_name = \"20_newsgroups_3categories\"     # see list of available datasets\n\nBASE_URL = \"http://localhost:5001/api/v0\"  # FreeDiscovery server URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "0. Load the example dataset\n---------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = BASE_URL + '/example-dataset/{}'.format(dataset_name)\nprint(\" GET\", url)\ninput_ds = requests.get(url).json()\n\n# To use a custom dataset, simply specify the following variables\ndata_dir = input_ds['metadata']['data_dir']\ndataset_definition = [{'document_id': row['document_id'],\n                       'file_path': os.path.join(data_dir, row['file_path'])}\n                      for row in input_ds['dataset']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Feature extraction (non hashed)\n------------------------------------\n1.a Load dataset and initalize feature extraction\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = BASE_URL + '/feature-extraction'\nprint(\" POST\", url)\nfe_opts = {'max_df': 0.6,  # filter out (too)/(un)frequent words\n           'weighting': \"ntc\",\n           }\nres = requests.post(url, json=fe_opts).json()\n\ndsid = res['id']\nprint(\"   => received {}\".format(list(res.keys())))\nprint(\"   => dsid = {}\".format(dsid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.b Run feature extraction\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = BASE_URL+'/feature-extraction/{}'.format(dsid)\nprint(\" POST\", url)\nres = requests.post(url, json={'dataset_definition': dataset_definition})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Calculate LSI\n----------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = BASE_URL + '/lsi/'\nprint(\"POST\", url)\n\nn_components = 100\nres = requests.post(url,\n                    json={'n_components': n_components,\n                          'parent_id': dsid\n                          }).json()\n\nlsi_id = res['id']\nprint('  => LSI model id = {}'.format(lsi_id))\nprint(('  => SVD decomposition with {} dimensions '\n       'explaining {:.2f} % variabilty of the data')\n      .format(n_components, res['explained_variance']*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Document Clustering (LSI + Birch Clustering)\n-----------------------------------------------\n3.a. Document clustering (LSI + Birch clustering)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = BASE_URL + '/clustering/birch/'\nprint(\" POST\", url)\nt0 = time()\nres = requests.post(url,\n                    json={'parent_id': lsi_id,\n                          'n_clusters': -1,\n                          'min_similarity': 0.55,\n                          #'max_tree_depth': 3,\n                          }).json()\n\nmid = res['id']\nprint(\"     => model id = {}\".format(mid))\n\nprint(\"\\n4.b. Computing cluster labels\")\nurl = BASE_URL + '/clustering/birch/{}'.format(mid)\nprint(\" GET\", url)\nres = requests.get(url,\n                   json={'n_top_words': 3\n                         }).json()\nt1 = time()\n\nprint('    .. computed in {:.1f}s'.format(t1 - t0))\ndata = res['data']\n\nprint(pd.DataFrame(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.b Hierarchical cluster visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ch = Digraph('cluster_hierarchy',\n             node_attr={'shape': 'record'},\n             format='png')\n\nch.graph_attr['rankdir'] = 'LR'\nch.graph_attr['dpi'] = \"200\"\n\nfor row in data:\n    ch.node('cluster_{}'.format(row['cluster_id']),\n            '{{<f0>{}| {{<f1> id={:03}  |<f2> N={} |<f3> sim={:.2f} }}}}'\n            .format(row['cluster_label'],\n                    row['cluster_id'],\n                    row['cluster_size'],\n                    row['cluster_similarity']))\n\n\ndef create_hc_links(node, ch, data):\n    for child_id in node['children']:\n        ch.edge('cluster_{}:f2'.format(node['cluster_id']),\n                'cluster_{}:f0'.format(child_id))\n        create_hc_links(data[child_id], ch, data)\n\n\ncreate_hc_links(data[0], ch, data)\n\ntmp_dir = os.path.join('..', '..', 'doc', 'engine', 'examples')\nif os.path.exists(tmp_dir):\n    ch.render('cluster_hierarchy', directory=tmp_dir, cleanup=True)\nelse:\n    ch.view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](cluster_hierarchy.png)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Delete the extracted features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = BASE_URL + '/feature-extraction/{}'.format(dsid)\nrequests.delete(url)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}