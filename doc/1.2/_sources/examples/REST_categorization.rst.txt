

.. _sphx_glr_examples_REST_categorization.py:


Categorization Example [REST API]
---------------------------------

An example to illustrate binary categorizaiton with FreeDiscovery





.. rst-class:: sphx-glr-script-out

 Out::

    0. Load the example dataset
     GET http://localhost:5001/api/v0/example-dataset/treclegal09_2k_subset

    1.a Load dataset and initalize feature extraction
     POST http://localhost:5001/api/v0/feature-extraction
       => received ['id']
       => dsid = f5320351651e4a6e

    1.b Start feature extraction (in the background)
     POST http://localhost:5001/api/v0/feature-extraction/f5320351651e4a6e

    1.c Monitor feature extraction progress
     GET http://localhost:5001/api/v0/feature-extraction/f5320351651e4a6e

    1.d. check the parameters of the extracted features
     GET http://localhost:5001/api/v0/feature-extraction/f5320351651e4a6e
         - analyzer: word
         - binary: False
         - chunk_size: 5000
         - data_dir: /home/ubuntu/freediscovery_shared/treclegal09_2k_subset/data/jobRun_4/XML_EXPORT_CONTENT/text_9
         - max_df: 1.0
         - min_df: 0.0
         - n_features: 100001
         - n_jobs: 1
         - n_samples: 2465
         - n_samples_processed: 2465
         - ngram_range: [1, 1]
         - norm: l2
         - parse_email_headers: False
         - stop_words: english
         - sublinear_tf: False
         - use_hashing: False
         - use_idf: False

    2. Calculate LSI
    POST http://localhost:5001/api/v0/lsi/
      => LSI model id = 0499b562aafb412a
      => SVD decomposition with 100 dimensions explaining 69.82 % variabilty of the data

    3.a. Train the categorization model
       category
    negative    63
    positive     5
    Name: document_id, dtype: int64 positive, 0 negative files
    ================================================================================ 
                LinearSVC   
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 16d005e9bf254374
        => Training scores: MAP = 0.815, ROC-AUC = 0.900, recall @20%: 0.800 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/16d005e9bf254374
         - method: LinearSVC
         - options: {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/16d005e9bf254374/predict
                 category  score
    document_id                 
    568516       negative  0.778
    3717184      negative  0.762
    454276       negative  0.762
    5171076      negative  0.760
    3568321      negative  0.759
    1803649      negative  0.754
    1252161      negative  0.753
    5166529      negative  0.752
    573049       negative  0.752
    885481       negative  0.751
    877969       negative  0.751
    3286969      negative  0.750
    274576       negative  0.750
    118336       negative  0.750
    5239521      negative  0.749
    3709476      negative  0.749
    319225       negative  0.749
    4941729      negative  0.749
    119716       negative  0.749
    4507129      negative  0.749
    4713241      negative  0.748
    2845969      negative  0.748
    4981824      negative  0.748
    4708900      negative  0.748
    320356       negative  0.748
    4831204      negative  0.748
    4359744      negative  0.747
    318096       negative  0.747
    1190281      negative  0.746
    1254400      negative  0.746
    ...               ...    ...
    4652649      negative  0.631
    36481        negative  0.631
    38025        negative  0.631
    199809       negative  0.630
    90000        negative  0.630
    4857616      negative  0.630
    268324       negative  0.630
    270400       negative  0.630
    80656        negative  0.630
    5022081      negative  0.630
    4968441      negative  0.630
    88804        negative  0.630
    1170724      negative  0.630
    79524        negative  0.630
    3073009      negative  0.629
    350464       negative  0.628
    984064       negative  0.627
    221841       negative  0.627
    846400       negative  0.621
    3240000      negative  0.620
    3222025      negative  0.620
    1046529      negative  0.620
    316969       negative  0.619
    822649       negative  0.619
    850084       negative  0.575
    833569       negative  0.567
    3422500      negative  0.552
    819025       negative  0.549
    3182656      negative  0.519
    3323329      negative  0.501

    [2397 rows x 2 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.982, ROC-AUC = 1.000, recall @20%: 1.000 
    ================================================================================ 
                NearestNeighbor  + LSI 
     ================================================================================
     POST http://localhost:5001/api/v0/categorization/
     Training...
         => model id = 60f81b7f0e0c4d9c
        => Training scores: MAP = 1.000, ROC-AUC = 1.000, recall @20%: 1.000 

    3.b. Check the parameters used in the categorization model
     GET http://localhost:5001/api/v0/categorization/60f81b7f0e0c4d9c
         - method: NearestNeighbor
         - options: {'algorithm': 'brute', 'leaf_size': 30, 'n_jobs': 1, 'radius': None}

    3.c Categorize the complete dataset with this model
     GET http://localhost:5001/api/v0/categorization/60f81b7f0e0c4d9c/predict
                 category  nearest_document_id  score
    document_id                                      
    54756        negative                75625  1.000
    1214404      negative              1218816  1.000
    3625216      negative              1218816  1.000
    3617604      negative              1218816  1.000
    1210000      negative              1218816  1.000
    73984        negative                75625  1.000
    4950625      negative                75625  1.000
    4813636      negative                75625  1.000
    652864       negative              1555009  1.000
    657721       negative              1555009  1.000
    851929       negative               150544  1.000
    75076        negative               150544  1.000
    1177225      negative               150544  1.000
    112225       negative               150544  1.000
    1115136      negative               150544  1.000
    1203409      negative               150544  1.000
    138384       negative               150544  1.000
    861184       negative               150544  1.000
    1297321      negative               150544  1.000
    868624       negative               150544  1.000
    1102500      negative               150544  1.000
    159201       negative               150544  1.000
    881721       negative               150544  1.000
    1087849      negative               150544  1.000
    37249        negative               150544  1.000
    35721        negative               150544  1.000
    30625        negative               150544  1.000
    29241        negative               150544  1.000
    27556        negative               150544  1.000
    1067089      negative               150544  1.000
    ...               ...                  ...    ...
    5750404      negative              5354596  0.086
    487204       negative                   81  0.084
    1798281      negative              4272489  0.084
    597529       negative              4272489  0.084
    1800964      negative              1846881  0.080
    599076       negative              1846881  0.080
    1159929      negative              5579044  0.077
    3481956      negative              5579044  0.077
    1164241      negative              5579044  0.077
    1155625      negative              5579044  0.077
    3489424      negative              5579044  0.077
    300304       negative              4498641  0.076
    490000       negative              2085136  0.072
    1582564      negative                 1024  0.072
    682276       negative                 1024  0.072
    544644       positive               844561  0.071
    611524       negative                 1024  0.059
    1503076      negative                 1024  0.059
    519841       negative              3254416  0.057
    546121       negative              4272489  0.056
    361201       negative              4272489  0.056
    628849       negative                 1024  0.055
    1532644      negative                 1024  0.055
    609961       negative                 1024  0.055
    1500625      negative                 1024  0.055
    1530169      negative                 1024  0.054
    627264       negative                 1024  0.054
    504100       negative              6007401  0.053
    524176       negative              4272489  0.038
    543169       negative              2442969  0.034

    [2397 rows x 3 columns]

    3.d Compute the categorization scores
     GET http://localhost:5001/api/v0/metrics/categorization
        => Test scores: MAP = 0.276, ROC-AUC = 0.666, recall @20%: 0.571 

    5.a Delete the extracted features (and LSI decomposition)
     DELETE http://localhost:5001/api/v0/feature-extraction/f5320351651e4a6e




|


.. code-block:: python


    from __future__ import print_function

    from time import time, sleep
    import os.path
    from multiprocessing import Process
    import requests
    import pandas as pd

    pd.options.display.float_format = '{:,.3f}'.format
    pd.options.display.expand_frame_repr = False

    dataset_name = "treclegal09_2k_subset"     # see list of available datasets

    BASE_URL = "http://localhost:5001/api/v0"  # FreeDiscovery server URL

    if __name__ == '__main__':

        print(" 0. Load the example dataset")
        url = BASE_URL + '/example-dataset/{}'.format(dataset_name)
        print(" GET", url)
        input_ds = requests.get(url).json()


        data_dir = input_ds['metadata']['data_dir']
        dataset_definition = [{'document_id': row['document_id'],
                               'file_path': os.path.join(data_dir, row['file_path'])}
                              for row in input_ds['dataset']]
        # create a custom dataset definition for ingestion

        # 1. Feature extraction

        print("\n1.a Load dataset and initalize feature extraction")
        url = BASE_URL + '/feature-extraction'
        print(" POST", url)
        res = requests.post(url).json()

        dsid = res['id']
        print("   => received {}".format(list(res.keys())))
        print("   => dsid = {}".format(dsid))

        print("\n1.b Start feature extraction (in the background)")

        # Make this call in a background process (there should be a better way of doing it)
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" POST", url)
        p = Process(target=requests.post, args=(url,),
                    kwargs={'json': {'dataset_definition': dataset_definition}})
        p.start()
        sleep(5.0)  # wait a bit for the processing to start

        print('\n1.c Monitor feature extraction progress')
        url = BASE_URL+'/feature-extraction/{}'.format(dsid)
        print(" GET", url)

        t0 = time()
        while True:
            res = requests.get(url)
            if res.status_code == 520:
                p.terminate()
                raise ValueError('Processing did not start')
            elif res.status_code == 200:
                break  # processing finished
            data = res.json()
            print('     ... {}k/{}k files processed in {:.1f} min'.format(
                        data['n_samples_processed']//1000, data['n_samples']//1000,
                        (time() - t0)/60.))
            sleep(15.0)

        p.terminate()  # just in case, should not be necessary

        print("\n1.d. check the parameters of the extracted features")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(' GET', url)
        res = requests.get(url).json()

        print('\n'.join(['     - {}: {}'.format(key, val)
              for key, val in res.items() if "filenames" not in key]))

        # 3. Document categorization with LSI (used for Nearest Neighbors method)

        print("\n2. Calculate LSI")

        url = BASE_URL + '/lsi/'
        print("POST", url)

        n_components = 100
        res = requests.post(url,
                            json={'n_components': n_components,
                                  'parent_id': dsid
                                  }).json()

        lsi_id = res['id']
        print('  => LSI model id = {}'.format(lsi_id))
        print('  => SVD decomposition with {} dimensions explaining {:.2f} % variabilty of the data'.format(
                                n_components, res['explained_variance']*100))

        # 3. Document categorization

        print("\n3.a. Train the categorization model")
        print("   {} positive, {} negative files".format(
              pd.DataFrame(input_ds['training_set'])
                .groupby('category').count()['document_id'], 0))

        for method, use_lsi in [('LinearSVC', False),
                                ('NearestNeighbor', True)]:

            print('='*80, '\n', ' '*10,
                  method, " + LSI" if use_lsi else ' ', '\n', '='*80)
            if use_lsi:
                # Categorization with the previously created LSI model
                parent_id = lsi_id
            else:
                # Categorization with original text features
                parent_id = dsid

            url = BASE_URL + '/categorization/'
            print(" POST", url)
            print(' Training...')

            res = requests.post(url,
                                json={'parent_id': parent_id,
                                      'data': input_ds['training_set'],
                                      'method': method,  # one of "LinearSVC", "LogisticRegression", 'xgboost'
                                      'training_scores': True
                                      }).json()

            mid = res['id']
            print("     => model id = {}".format(mid))
            print('    => Training scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res['training_scores']))

            print("\n3.b. Check the parameters used in the categorization model")
            url = BASE_URL + '/categorization/{}'.format(mid)
            print(" GET", url)
            res = requests.get(url).json()

            print('\n'.join(['     - {}: {}'.format(key, val)
                  for key, val in res.items() if key not in ['index', 'category']]))

            print("\n3.c Categorize the complete dataset with this model")
            url = BASE_URL + '/categorization/{}/predict'.format(mid)
            print(" GET", url)
            res = requests.get(url, json={'subset': 'test'}).json()

            data = []
            for row in res['data']:
                nrow = {'document_id': row['document_id'],
                        'category': row['scores'][0]['category'],
                        'score': row['scores'][0]['score']}
                if method == 'NearestNeighbor':
                    nrow['nearest_document_id'] = row['scores'][0]['document_id']
                data.append(nrow)

            df = pd.DataFrame(data).set_index('document_id')
            print(df)

            print("\n3.d Compute the categorization scores")
            url = BASE_URL + '/metrics/categorization'
            print(" GET", url)
            res = requests.post(url, json={'y_true': input_ds['dataset'],
                                           'y_pred': res['data']}).json()

            print('    => Test scores: MAP = {average_precision:.3f}, ROC-AUC = {roc_auc:.3f}, recall @20%: {recall_at_20p:.3f} '.format(**res))

        # 4. Cleaning
        print("\n5.a Delete the extracted features (and LSI decomposition)")
        url = BASE_URL + '/feature-extraction/{}'.format(dsid)
        print(" DELETE", url)
        requests.delete(url)

**Total running time of the script:** ( 0 minutes  10.110 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: REST_categorization.py <REST_categorization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: REST_categorization.ipynb <REST_categorization.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
